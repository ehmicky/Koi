
               
   CHECK-SPEED  
               



Find better name

Add keywords (GitHub, package.json)

Allow TASK to be a FUNC() as a shortcut to { main: FUNC }

Async:
  - run one main() at a time
  - run one main()+parameters() at a time
     - but run its OPTS.repeat in parallel
  - for values|cleanup()
     - automatically follow PROMISE if return one
     - but remain sync otherwise

On thrown exceptions in parameters|main|cleanup():
  - exit code 1
  - stop:
     - if OPTS.bail true (def: false), whole run
     - otherwise current main()+parameters repetitions
  - relies on p-times OPTS.stopOnError true (default value)
  - RESULT.failure OBJ:
     - error ERROR.stack
     - errorIndex NUM:
        - incrementing counter
        - used to display errors as footnotes during reporting
  - RESULT.failed BOOL: if any RESULT.failure set
  - try/catch block should include `performance.now()` so it does not skew timing

More input validation, including jest-validate
  - including return value of `values()`

OPTS.timeout NUM (in secs)
  - for whole run
  - checked after each iteration
  - make whole run stop with exit code 1
  - RESULT.failure.timeout true on last result
  - def: 10 minutes

CLI pointing to file:
  - doing named exports for each TASK:
     - TASK.name defaults to name of the export
  - OPTS are CLI options
     - can be config file too
  - default to benchmarks.js or benchmarks/index.js or benchmarks/main.js

Reporters:
  - FUNC(RESULT_ARR)[->STR]
     - if STR, either printed to console or put in file (if OPTS.replace)
  - OPTS.reporters 'MODULE'_ARR
  - types:
     - silent
     - JSON
     - CLI list
     - CLI table
     - Markdown list
     - Markdown table
  - CLI|Markdown list:
     - follow the formatting I used in fast-cartesian example
        - simple list for TASK with no TASK.parameters
  - CLI|Markdown tables:
     - parameters as x axis, mains as y axis
  - default reporter:
     - CLI table if more than half of cells would be filled, and some TASK.parameters are defined
     - CLI list otherwise
  - counter:
     - show incrementing counter or progress bar
     - for any reporter except silent
  - sorting:
     - sort main() from fastest to slowest (using average of parameters)
     - sort parameters() from fastest to slowest (using average among main() with same name)
  - OPTS.replace 'PATH':
     - update file
        - any format, but the inserted content is Markdown
     - looks for delimiters:
        - "check-list-start" and "check-list-end"
           - remove anything in-between
        - there can be other things on the line (e.g. <!-- -->), but whole line is kept
        - if only "check-list-start" is found, assume "check-list-end" is right after it
           - this allows documenting only adding "check-list-start" the first time
        - no parsing needed
     - for any reporter
        - each reporter must declare how to wrap it:
           - nothing (silent, Markdown)
           - ``` ``` (CLI)
           - ```TYPE ``` (JSON)

Add a Gulp task to my gulp-shared-tasks

Add more stats in RESULT.duration:
  - mean NUM
  - average NUM
  - deviation NUM
  - variance NUM
  - min|max NUM
  - percentiles NUM_ARR
  - all NUM_ARR
  - margin of error, relative margin of error, standard error of mean

OPTS.thresholds OBJ:
  - same members as RESULT.duration
  - if above threshold:
     - exit code 1
     - on RESULT.failure.thresholds OBJ (with actual time that failed)

OPTS.platforms STR (use browserlist and PACKAGE.engines)
  - run in different browsers and Node versions
     - i.e. should probably enforce ESM
  - create one RESULT per platform, with different RESULT.system

RESULT.system OBJ: hardware and software info

Commercial offer:
  - Dashboard:
     - show time series (i.e. keep history)
        - should not lose history when change only the `title` of the function|variant
     - nice data visualization
     - should show function bodies
  - Sharing like jsperf:
     - allow users to run in their own browsers
  - PR bot
  - notifications
  - user should report benchmark results to our API
     - like Codecov does
     - i.e. we do not pay for infrastructure cost, except simple CRUD API to store benchmark results
     - should be integrated with CI (i.e. use `ci-info`)
  - pricing:
     - free for open source
     - pay per private repo
