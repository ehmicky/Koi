
               
   CHECK-SPEED  
               



Go through whole thing

Add lots of comments in the code, especially describing algorithm and constants

Rename to spyd

More input validation, including jest-validate

On error:
  - always stop whole run
     - no OPTS.bail
  - print error on console
  - exit code 1
  - do not run reporters
  - thrown exceptions in main|before|after() should show extra error message, but behave the same otherwise
  - including child process fail on load or exit code
     - ignore stderr though

OPTS.require "PATH"_ARR:
  - use node --require
  - goal: babel/register, etc.

Reporters:
  - FUNC(RESULT_ARR, REPORTER_OPTS)[->STR]
     - if STR, either printed to console or put in file (if OPTS.replace)
  - OPTS.reporters 'MODULE'_ARR
  - REPORTER_OPTS:
     - passed by user as OPTS.REPORTEROPT, passed to FUNC as OPTS.OPT
  - types:
     - silent
     - JSON
     - CLI list
     - CLI table
     - Markdown list
     - Markdown table
  - CLI|Markdown list:
     - follow the formatting I used in fast-cartesian example
        - simple list for TASK with no TASK.parameters
  - CLI|Markdown tables:
     - parameters as x axis, mains as y axis
  - default reporter:
     - CLI table if more than half of cells would be filled, and some TASK.parameters are defined
     - CLI list otherwise
  - sort RESULT_ARR:
     - sort main() from fastest to slowest (using average of parameters)
     - sort parameters() from fastest to slowest (using average among main() with same name)
  - show standard devation with +|- (to give idea of precision and whether should increase duration)
     - when deviation is 0 (only one `time`), should display differently

Duration reporting:
  - use lowest unit, with minimum 10 (i.e. 2 digits)
  - integers only

REPORTER_OPTS.output 'PATH':
  - def: "-" (stdout)
  - if file contains string "benchtap-start" and "benchtap-end", insert instead:
     - insert content as is, with no wrapping
     - agnostic to:
        - format of the file to modify
        - format of the inserted content
        - users need to pick ones that make sense, e.g. Markdown reporters for Markdown files
     - looks for delimiters:
        - "check-speed-start" and "check-speed-end"
           - remove anything in-between
          - require both. Reason: when moving it around the file, user should be aware that both should be moved
        - there can be other things on the line (e.g. <!-- COMMENT --> or #COMMENT), but whole line is kept
        - no parsing needed

Baseline reporting:
  - OPTS.baseline "PATH"|BOOL (def: sibling to benchmarked file, e.g. "benchmark.js" -> "benchmark.baseline.json")
     - if file exists, compare current results with baseline results and pass comparison to reporters
     - reporters should show it after the median, e.g. green|red down|up arrow with time difference
  - OPTS.save BOOL (def: false):
     - save current results to OPTS.baseline

"Benchmarks created by [check-speed](...)" in reporters:
  - OPTS.credits BOOL (def: true if insert mode)

Reporter showing advanced stats
  - e.g. graphs in terminal

Reporter where the tasks are in both axis, and the cells are the difference in %

Progress reporters:
  - separate from final reporters
  - OPTS.progress "MODULE"_ARR
  - called at regular intervals
  - called with:
     - percentage
     - current task
     - current task stats
  - types:
     - silent (def when OPTS.reporters 'silent')
     - progress bar
     - spinner with task name and current median
     - both above (def)
  - not shown in non-interactive terminal or in CI

OPTS.limit.TASK_ID NUM
  - maximum median for that task
  - if above:
     - exit code 1

Add a Gulp task to my gulp-shared-tasks

RESULT.system OBJ: hardware and software info

OPTS.platforms STR (use browserlist and PACKAGE.engines)
  - run in different browsers and Node versions
     - i.e. should probably enforce ESM
  - create one RESULT per platform, with different RESULT.system
  - abstract to own package
  - should allow adding platforms as plugins

Separate now.js to its own package

Separate resolution.js to its own package

Separate stats to its own package
  - compare with existing packages

Separate measuring part to its own package
  - child processes might be able to spawn only this instead of the full check-speed package

Logo:
  - make it look like a timewatch
     - maybe show 58:90 and highlight in a different color the lines that form SPYD

Promote:
  - add keywords (GitHub, package.json)

Features:
  - most precise and accurate benchmarking
  - pretty reporting
  - comparison with previous benchmarks
  - performance testing
  - automatically insert latest benchmarks into your documentation
  - custom reporters

Commercial offer:
  - reporting dashboard:
     - show time series (i.e. keep history)
        - should not lose history when change only the `title` of the function|variant
     - nice data visualization
     - should show function bodies
  - code editor for benchmark files:
     - run benchmarks (inside browser not on our servers)
     - send benchmark results to API (like what users would do on CI otherwise)
     - show results from API
     - i.e. can be used like jsperf
  - Sharing like jsperf:
     - allow users to run in their own browsers
  - PR bot
  - notifications
  - user should report benchmark results to our API
     - like Codecov does
     - i.e. we do not pay for infrastructure cost, except simple CRUD API to store benchmark results
     - should be integrated with CI (i.e. use `ci-info`)
  - pricing:
     - free for open source
     - pay per private repo
