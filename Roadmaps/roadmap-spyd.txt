
        
   SPYD  
        



Combination duration:
  - wait 1 second before showing "Starting..." or "Exiting..." to avoid flicker
  - `duration` should not include time to load tasks and spawn processes
     - reasons:
        - adding imports to tasks does not change number of measures
        - adding slow-to-load tasks does not change other tasks duration
     - how: right before starting first sample, set progressState.benchmarkEnd, as opposed to before load
        - before this, should set progressState.description "Starting..."
  - use a single timestamp for sample durations:
     - right before starting first sample, set the combination's state.sampleDurationTimestamp now()
     - do not record sampleStart anymore
     - at end of each sample, update state.sampleDurationTimestamp now()
     - compute sampleDurationLast with differences between two state.sampleDurationTimestamp
  - combination stop:
     - getRemainingCombinations() should exclude any combinations with either:
        - state.loops < combinationMaxLoops
           - combinationMaxLoops is computed once for all combinations (so the `combinations` does not to be passed down to each combination)
           - it is MAX_LOOPS / combinations.length
        - state.completed true
           - initially false, i.e. each combination always measured at least once
     - when a combination ends:
        - compute sample duration
        - if combinationDuration + sampleDurationMean > CONF.duration:
           - send empty params OBJ to runner so it performs afterAll and exits
           - compute cleanupDuration = now() - state.sampleDurationTimestamp
           - progressState.benchmarkEnd += (CONF.duration - (combinationDuration + cleanupDuration))
              - if combination had time left, progress counter will jump down
              - if combination was slower (including only measured once and was over CONF.duration), progress counter will jump up
           - set state.completed false

Fix `exec`, e.g. `stdio` must be [`ignore`, `inherit`, `inherit`]
  - pSetTimeout() should be either unref() or clearTimeout(), otherwise it will hold the process

Fix CLI runner

Put `return.js` into smaller function

Fix `src/combinations/main.js` that is currently hardcoded
  - instead of exporting tasks OBJ_ARR, named exports: beforeAll|beforeEach|main|afterEach|afterAll
  - add comment why each task file contains a single task: lower loadCost

Go through whole code, looking for bugs

Precision:
  - compare precision:
     - compare with multiple processes:
        - variance between combinations of single benchmark, vs between single combinations of different benchmarks
        - median vs standard deviation vs variation between processes
        - small CONF.duration vs big CONF.duration
  - note: using a "for loop" without spyd does work:
     - increasing the count makes the results more and more precise
     - the first 2 loops (regardless of the total count) always seem to be different from others
  - check if using a fixed, low amount of processes helps with precision???
  - find ways to improve precision even more???

Live updating:
  - steps:
     - reporter.report()->STR:
        - done after each measures aggregation:
           - counted as part of the `aggregateDuration`
           - unless repeatInit false
              - reason: if repeatInit false, measures will be removed, which would create confusing reporting (e.g. for min|max)
              - other reason: during repeatInit false, stats change a lot, creating flicker
     - do I/O using the last reporter.report() STR
        - done during progress reporting interval function
           - not counted as part of the `aggregateDuration`
  - both steps are:
     - also initially done right after combinations are available, showing no stats yet
     - only done if all of:
        - reporter.progress true (def: false)
        - reportConfig.output "-"
        - CONF.quiet false
  - call reporter.report()->STR with same arguments as the final reporter.report():
     - including result being normalized
     - including having information from initial listResults() (e.g. for previous combinations and diff)
     - including all possible result.combinations, even ones not measured yet
     - excluding CONF.show, always empty
  - if reporter.progress false, reporter.report() can be async. If true, cannot.
  - progress reporter is appended to it:
     - performed right after each live reporting
  - screen refreshing:
     - refresh whole screen at the beginning
        - use `signal-exit`
        - experiment if there is a way to refresh partial screen instead of whole screen
           - it should still work if user types newline or characters
     - each update should refresh the whole screen with the new content
        - but by printing over it, not clearing it first, to avoid flickering
        - i.e. need to padRight() the new content if the old content was larger
  - new progress.*() shape:
     - since core now handles refreshing the screen
     - progress.update():
        - must return a STR
        - must be sync
     - remove progress.start|stop()
  - limit the amount of changes of the general shape of the output between the initial call and the final one, to make it look nicer
     - e.g. tables should be initially shown with all rows|columns and empty cells

Once mode:
  - CONF.duration 0
  - measures each combination exactly once
     - wait for repeatInit true though
  - progress reporting:
     - pass percentage undefined
     - instead of durationLeft, pass just duration
        - incrementing, not decrementing
        - time units increase too: SSs, then MMmSSs, then HHhMMmSSs

Infinite duration:
  - CONF.duration -1
  - measures forever
  - default value: -1 if interactive TTY, 0 otherwise
  - progress reporter: like CONF.duration 0
  - when manually interrupting benchmark:
     - keep both progress reporter and live reporter printed
     - report all other reporters too
  - validate that CONF.save is not true
  - progressState.description "Type CTRL-C to exit"
     - or equivalent key on Windows

CONF.concurrency NUM
  - validate that CONF.concurrency NUM is integer >=1
  - each sample spawns NUM processes in parallel
     - in `bench` command, but not in `exec` command
     - start|end group of processes together
     - use same `params`, including `maxLoops`
     - if one process fails
        - the other ones should continue (for cleanup)
        - but the sample should then propagate error
     - measureCost computation should use the same amount of parallel processes
  - add code comment that:
     - CONF.concurrency is meant to measure cost of parallelism
        - both CPU and I/O parallelism
     - if task is I/O bound, it can also improve precision by performing more measures, at the cost of accuracy (due to cost of parallelism)
        - the number where parallel processes start competing for CPU depends on how much duration the task spend on CPU vs I/O
        - above that number:
           - median measure increases much more
           - precision decreases much more
     - move the current code comment from src/measure/combination.js (about spawning processes serially)
  - handle spawn errors due to too many processes at once
     - try to remove process limit with ulimit, and see if another error can happen with a high CONF.concurrency, e.g. too many open files

isAsync:
  - initial check for isAsync:
     - execute func once, without await
     - check if return value is promisable (using p-is-promise)
     - sets func.isAsync BOOL (originally undefined)
     - if isAsync, await return value
  - do the above when func.isAsync undefined && repeat 1
     - add code comment that repeat should always be 1 when func.isAsync undefined, and this probably won't change. It is more of a failsafe.
  - do the above in a `sync_async` dir, next to `sync` and `async` dirs
  - do the above independently for beforeEach, main and afterEach
  - always use await on beforeAll|afterAll, i.e. allow both sync and async
  - remove task.async BOOL

Quantiles|histogram:
  - persist in stores
  - some stats should have a space-efficient shape for stores, but be denormalized on load:
     - histogram:
        - denormalized: OBJ_ARR: low, high, frequency
        - normalized: ARR of [high, frequency]
     - quantiles:
        - denormalized: OBJ_ARR: percentage NUM, value NUM
        - normalized: NUM_ARR
     - both: use difference from median in durations
  - show in `debug` reporter

reporter.debugStats BOOL
  - def: false
  - true for `debug` reporter
  - if false, do not pass:
     - mean
        - add comment that we must ensure median is the main one used, so different reporters are consistent, and also because it is used in sorting combinations, and also it is less precise
     - times
        - add comment that it is a bad indicator of precision, and also might be confused as an indicator of speed due to other benchmark libraries showing it like that
     - loadCost, measureCost, processes, repeat, loops

Sort all the code comments in `measure/**` and the `node|cli` runners. It's a bit messy right now, and some might be outdated

CONF.report|run|store|progress:
  - CONF.report|run|store|progress 'NAME'_ARR (enable|disable)
  - CONF.report|run|store|progress_NAME_PROP VAL (config)
     - can set config even if disabled. Does not enable.
  - reasons:
     - flat simpler than nesting
     - single delimiter character. No mixing several like - _ .
     - distinction selecting adapters vs configuring them
     - allow different users and programming languages to use prefered characters in ids
     - works unescaped with YAML and JSON
     - easy to understand when both CONF.VAR and CONF.report_{reporterId}-PROP are possible. The second is just like a selector/namespace
  - remove the `addRunners()` function which split CONF.run to CONF.run|runners
  - environment variables:
     - use _ as delimiter instead of __
     - no need for `set()` nesting anymore since all config properties are flat now

ID validation:
  - for user-defined (task|input|system|mergeId):
     - [[a-zA-Z0-9]._-]+
     - no empty string
  - for plugins (report|run|store|progress):
     - [a-z][a-z0-9]*
     - no empty string
     - no _
        - reason: not allowed in npm package name
        - reason: used as config property delimiter
     - no .
        - reason: not allowed in npm package name
     - no -
        - reason: confusing when mixed with _ delimiter in config properties
        - reason: not friendly in envvars
     - force module name to spyd-report|run|store|progress-NAME
  - default mergeId in CI:
     - use a more generic characters replacement logic, with a slugify library, using the list of allowed characters in mergeId

Add comment that we enforce [a-z][a-z0-9_]* in configuration property names
  - in core (as opposed to plugins), we try to avoid _ too
  - reasons:
     - no mixed case, because it is not common in CLI flags nor environment variables
     - consistent option name across spyd.yml, CLI flags, envvars, programmatic
     - no multiple delimiters

Validate that there are no duplicate ids for tasks|inputs|systems|propSets|runners
  - reason: allows using id only (without specifyig the type) in some contexts, e.g. CONF.include|exclude

runner.config.PROP.example STR[_ARR]
  - for all plugins: reporter, progress, runner, store
  - meant for validation, using jest-validate (same validation as for CONF.*):
     - validate against unknown props
     - if ARR, use multipleValidOptions()
  - required

CONF.system:
  - CONF.system "systemId"
     - id does not need any no slugification
     - def: "default_system"
        - reason: unlikely to conflict with a taskId or inputId
     - title:
        - not needed due to titles.yml
        - def: same as default id
           - not shown in core reporters (since sharedSystem is top-level)
     - no variables
        - including {{ENV_VAR}}, {{os}}, {{os_full}}
        - instead can use:
           - shell, e.g. subshell and environment variable expansion
           - passing SPYD_SYSTEM environment variable from caller
  - reporting|measuring:
     - the current partialResult only uses one system: CONF.system
        - only `bench` command
     - CONF.include|exclude allows reporting several systems
        - `bench|show|remove` commands
        - either from current benchmark (with CONF.merge) or previous benchmarks
        - does not apply to measuring
        - current CONF.system always included
  - add comment that system is only for out-of-spyd env: hardware, OS, git branch, env vars, etc.

result.systems:
  - still an OBJ_ARR, one per systemId
  - result.systems[0] -> result.sharedSystem
     - created on results load
  - result.systems[*]:
     - id STR
     - title STR
        - def: same as id
     - machine: os|memory|cpu
     - versions OBJ
        - all runner.versions shallow merged
        - not versions.RUNNER.VAR: all runners shallow merge their versions OBJ, using CONF.run ARR order as priority order
     - git
        - not result.git
     - ci "URL"
        - not OBJ, and not result.ci
     - no more config nor runConfig
        - should use propSets instead

Remove commands dimension:
  - CONF.run_node_versions -> CONF.run_node_version (only one version)
  - runner.commands() returns a single OBJ instead of OBJ_ARR:
     - should use propSets instead to perform several runConfig
     - commands is not a input-like dimension anymore, including in:
        - combination.name|columnName
        - combination.commandRank
        - combination.previous
        - combinations sorting
        - duplication removal
        - commandId in CONF.limit
        - `show`/`remove` command filtering
        - result.commands[Pretty]
     - returned OBJ properties:
        - spawn ['FILE', 'ARG',...]
        - spawnOptions OBJ (def: {})
        - not needed anymore:
           - id -> not needed anymore since no more targetting
           - title|description -> runner.id|title
  - remove any instances of the word "command", except for CLI commands, to avoid confusion
     - commandConfig -> runConfig

runner.commands(runConfig):
  - rename to runner.launch(runConfig)
  - instead of returning [PROMISE_]OBJ, return [PROMISE_]STR, i.e. ['FILE', 'ARGS',... [, OBJ2]]
     - OBJ2 is optional spawnOptions
  - can optionally be directly a STR instead of FUNC()->[PROMISE_]STR

runner.versions
  - instead of runner.system
  - either OBJ or FUNC(runConfig, launchCommand)->[PROMISE_]OBJ
     - launchCommand is STR_ARR returned by runner.launch()
     - OBJ values can be either STR (direct value) or STR_ARR (command to retrieve stdout from, all called in parallel)
  - required
  - meant for software versions, mode (e.g. type of shell) and options

propSets:
  - name:
     - propSet: whole dimension
     - propItem: each item in a propSet
     - called "configuration property sets" in comments and documentation
  - specified by either:
     - passing ARR to specific CONF.*
        - validate no duplicate values in that ARR
     - merging results with different VALs for specific CONF.*
        - i.e. remove that results with different CONF.* cannot be merged
  - only on any CONF.* that can change the results:
     - CONF.concurrency
     - CONF.duration
        - not documented since this is generally not a good idea
        - however, this ensures that when merging results, different durations are clearly marked as such
     - any CONF.run_{runnerId}_*
        - cartesian product only to combinations with that runner
  - each propSet is a separate dimension, distinct from other propSets:
     - in CONF.include|exclude
     - in combination.columnName: several STR
     - result.propSets OBJ_ARR_ARR, not OBJ_ARR
     - combination.propSets ARR
  - propItemId:
     - property key appended by 0-based index, e.g. "concurrency_0" or "run_node_version_2"
        - index in current benchmark only (not previous ones)
        - when adding a new propItem through CONF.merge, use incremented index
     - used when selecting with CONF.include|exclude|limit
        - can optionally omit repeated part, e.g. concurrency_0,3,4
  - propItemValue:
     - property VAL
     - used as identifier when comparing between combinations (including between different benchmarks), using util.isStrictDeepEqual()
  - propItemTitle:
     - returned by runner.config.PROP.title(VAL)->STR
     - optional. Default function:
        - `${PROP} ${VAL}`
        - PROP is titleized, e.g. aa_bb_cc -> Aa bb cc
        - VAL: String() on STR|NUM|BOOL|null, max decimals on FLOAT
     - truncate result with ellipsis if too big
  - set on result.* like other dimensions:
     - for combinations sorting, mean, rank, selection, etc.
     - result.propSets OBJ_ARR_ARR: id STR, value VAL, title STR
     - combination.propSets OBJ_ARR: id STR, value VAL, title STR
  - just like tasks and inputs, only reported in main reporting table, not in system info below it
  - if several propItems have different runner.versions.VAR VAL, they are concatenated as a  result.systems[*].versions.VAR ARR
     - printed as a comma-separated list by reporter prettify logic
     - does not mention which propItem used which ones. It should be obvious enough from propItemTitles

CONF.include|exclude STR_ARR
  - possible combinations are cartesian product of: tasks, inputs, runners, propSets, systems
  - format:
     - CONF.include|exclude STR_ARR
        - def:
           - include: all
           - exclude: none
        - combination is used if included and not excluded
     - STR_ARR: does union
        - each STR do not need to share same dimensions
     - STR is a space-separated list of groups
        - groups are intersected
        - groups must all be from different dimensions
     - each group is a comma-separated list of IDs
        - all IDs must be from same dimension
        - can prepend ! to whole group to invert its selection
           - done before intersecting with other groups
        - no space allowed around comma
  - remove the special parsing with CLI flags to allow ARR values using comma-separated lists
  - no more need for:
     - CONF.tasks|inputs
     - task.inputs
  - CONF.limit should be STR_ARR with same format as CONF.include
     - except each STR is prepended with percentage (then space) and IDs are optional

CONF.settings "DIR"
  - def: first .[/...]/benchmark
     - "benchmark", not "benchmarks"
  - in CLI, is a normal flag (not positional)
  - remove CONF.cwd
  - used for task files
  - used for results file (SETTINGS/results.ndjson)
  - used as the cwd for CONF.output|insert
  - used for config file

Config file:
  - merge several:
     - in priority:
        - CLI flag --config
        - environment variables
        - CONF.settings/[.../]spyd.yml
        - ./[.../]spyd.yml
        - home dir  using `env-paths` `config`, i.e. /home/USER/.config/NAME, /Users/USER/Library/Preferences/NAME, C:/Users/USER/AppData/Roaming/NAME/Config
     - need two rounds, since CONF.settings/spyd.yml might be found using CONF.settings from other locations
  - shallow merge

CONF.run "RUNNER_ID"_ARR
  - default value
     - only bundled runners
        - reason: runners in CONF.run not installed fail, and we do not want to force npm installs
     - def: ["node", "cli"]
     - should not put several runners with same|shared EXTs
  - is a dimension, i.e. can CONF.include|exclude
     - only cartesian product to tasks with matching file extension
  - add code comment that we use explicit CONF.run instead of:
     - using code comment
        - bad performance with big files
        - transpiling removing comments
        - does not work in compiled binaries
     - using filenames:
        - does not work will with multiple runners per task
        - leads to odd filenames when runner and extension are similar|same
     - guessing using require()
        - too implicit/magic
        - would also find dependencies dependencies
        - does not work well with bundled runners

Task files selection:
  - SETTINGS[/*]/TASK_ID.task.[RUNNER.]EXT
     - allows for both regular files and 1-depth directories
  - no more CONF.files (CLI positional argument)
  - use `junk` to filter out
  - only task files with matching runners
     - only if present in CONF.run
     - based on runner.extensions "EXT"_ARR
        - EXT can have dot in it, e.g. 'EXT.EXT2'
     - can override with RUNNER in filename, in which case runner.extensions is ignored
        - must still be present in CONF.run
        - possible goals:
           - if runner.extensions does not contain the extension wanted by user
           - allow two files with same taskId, same file extension but different runners
              - e.g. taskId.task.node.js and taskId.task.browser.js
     - single task file can target several runners, which spawns several combinations
     - no errors if no matching runners
        - reason: selecting with CONF.run
  - validate that no two task files have same taskId + runner
     - but can have same taskId and different runner, or vice-versa
  - the resulting tasks can all be selected with CONF.include|exclude
  - no need to return taskId anymore in runner load()

Better titles:
  - specified in titles.yml
     - OBJ:
        - key is id
        - value is title STR
     - can be any dimension: task, input, system, propSets, runner
     - reasons:
        - no need to wait for processes spawn to start displaying task titles
        - single place for users to specify titles for tasks, inputs and systems, i.e. simpler
        - simpler for runner, which do not need to handle titles
  - default title:
     - task, input, system: same as id
     - propSets: runner.config.PROP.title()
     - runner: runner.title
  - CONF.show "titles"
     - if absent, show ids, not titles
        - except propSets, which always show titles
        - reasons:
           - making id clear to users for CONF.include|exclude
     - def: absent
  - remove title specified in:
     - task.title
     - inputs
     - no more need to return inputTitle|taskTitle from runner.load()

inputs.yml:
  - instead of inputs inside tasks
  - located at SETTINGS/inputs.yml
  - use JSON_SCHEMA js-yaml option
  - OBJ:
     - key is id
     - value is value
  - runner.benchmark() gets `input` value instead of inputId
  - the resulting inputs can all be selected with CONF.include|exclude
     - no more need to return inputId|inputTitle from runner.load()

Multiple inputs dimensions:
  - allow inputs.yml to be either:
     - OBJ: single dimension
     - OBJ_ARR: multiple dimensions of inputs, i.e. cartesian product between them
  - runner gets array of input values
     - not single input value
        - even if only one dimension
     - nor variadic arguments
        - reason: it would require additional effort from runner to parse than just getting an array

CONF.info|context -> CONF.show STR_ARR among 'system', 'metadata'
  - if no:
     - 'system': pass `undefined` to reporters for result.sharedSystem|systems[*].machine|versions|spyd
     - 'metadata': pass `undefined` to reporters for result.sharedSystem|systems[*].git|ci and result.id|timestamp
  - default value:
     - has "system" if CONF.system defined
     - has "metadata" if `show|remove` command

Spyd link in reporter
  - should be presented as spyd version instead:
     - "Benchmarked by [spyd vX.Y.Z](URL to GitHub release)
  - persist result.spydVersion "X.Y.Z"
     - when merging, only the lowest one is kept
     - on load, normalized to results.spyd OBJ:
        - version "X.Y.Z"
        - release "URL" to GitHub release
  - remove CONF.link BOOL
     - instead, make it part of CONF.show "system"
        - when not present, result.spyd should be undefined
        - should also be undefined when printing to interactive terminal

Variables in `cli` runner:
  - remove user-defined `variables`. Can use either subshells, or command wrapper instead
  - add code comment that {{main}} is purposely not provided so users only put what they want to measure in main, not cleanup code for "after"
  - available variables (in lowest priority order):
     - {{ENV_VAR}}
        - use process.env as is, i.e. case sensitive on Unix, case insensitive on Windows
     - {{before}}, {{main}}
     - {{inputId}}

combination.name|columnName:
  - task dimension not present if all combinations have same value (like other dimensions)
     - exception: if single dimension, show only task
  - columnName order is input, system, runner, propSets
  - if there are runner-specific propSets
     - must be last
     - empty values (when on different runners) removed
        - i.e. different propSets for different runners might be aligned together
     - columnName arrays should all have same length, by appending empty strings
        - i.e. if one runner has 1 propSet, and another has 2, the first gets an empty string appended

Persist result.tasks|inputs|systems|commands:
  - only data which cannot be computed: id|title
     - mean|rank should be computed during load normalization instead
  - do not persist result.combinations[*].*Title
     - add those during load normalization instead
     - only persist result.combinations[*].*Id|stats

Execute `listResults()` earlier:
  - after config retrieval
  - before:
     - `bench` command: combination list computing
     - `show|remove` command: retrieving specific result (i.e. split `getFromStore` into two)
  - reasons:
     - with CONF.merge, allows skipping already saved combinations
        - including when continuing stopped benchmark
     - show previous|diff during progress|live reporting
     - fail benchmark fast if problem with store

After listResults(), core should normalize partialResults to results:
  - perform an array of reducing functions:
     - meant for migration, when a new release of spyd is making changes to result properties
     - array is empty for the moment
  - filter by tasks|inputs|systems|propSets
  - sort by partialResult.timestamp
  - group partialResults to result using partialResult.mergeId
     - partialResult.id -> not kept in result
     - partialResult.mergeId -> result.id
  - silently filter out duplicate combinations (same mergeId+taskId+inputId+systemId+propItemValue)
     - reason: might happen if two results with same mergeId ran in parallel
     - keep one with earliest timestamp

store.add(result) -> store.add(partialResult)
  - i.e. append only, not merged with previous ones
  - same for addResult()

Add in comment and --help that CONF.merge is meant only for doing a single benchmark but incrementally:
  - parallelize benchmarks across identical machines (including in CI): same mergeId, same systemId
  - benchmark across different machines|hardware|software (including in CI): same mergeId, different systemId
  - continue stopped benchmark

When merging combination and there is a duplicate of same mergeId and taskId+inputId+systemId+propItemValue:
  - different os|cpu|memory|git:
     - throw and suggest to either use a different systemId, or make a different benchmark
     - reason: merge is meant for incremental benchmarks, i.e. combinations must be comparable
  - different CI build|job:
     - merge:
        - if one has no CI build|job URL, use other
        - if same CI job URL, use it
        - if same CI build URL, use it
        - if several CI build URLs, use the new one
     - reason: benchmark parallelized on several machines
  - different timestamp: keep earliest
  - different CONF.*:
     - if propItemValue: different propItems
     - otherwise: ignored
  - no difference check if different systemId
     - only appends to result.systems
     - reasons: using systems to compare machines, git branches, etc.

CONF.merge skipping previous combinations:
  - if CONF.merge in `bench` command, do not measure (but still report) combinations already saved
  - reason: CONF.merge is meant for incremental benchmarks, including continuing stopped benchmark

Saving stopped benchmark:
  - when manually interrupting benchmark (SIGINT, etc.)
  - serialize current measuring state (including all `measures`) to file
     - in GLOBAL_CACHE_DIR/HASH/stopped_benchmark.json
        - HASH is SHA1 of normalized absolute file path of CONF.settings
  - only last stopped benchmark (for a given CONF.settings) is saved
  - CONF.continue BOOL:
     - if true and there is a stopped_benchmark.json, use it to continue the last stopped benchmark
     - must use similar settings
        - e.g. main config values (like duration), combinations ids
        - figure out the exact set of settings to compare.
           - some are ok to change, e.g. reporting-related
  - remove CONF.merge "" to mean "same|last result"

Deltas:
  - in `show|remove` commands, and CONF.since|diff
  - computed by core
  - based on listResults() output, after tasks|inputs|systems filtering
     - reason: if a user is doing `bench` always filtered for specific tasks|inputs|systems, without using CONF.merge (e.g.  each task is a library, and is only recomputed on a new version of the library), then `show` or default CONF.diff 1 should compare each combination to the latest which had same taskId|inputId|systemId
        - should document this, since it is an alternative to CONF.merge, with similar goals for settings slow or with many dimensions
  - can be:
     - absolute timestamp
     - relative duration like "3m"
     - NUM
     - mergeId
  - operates on results, not on partialResults
  - when using timestamps|duration, should retrieve the full result
     - even if some partialResult are before, some after the timestamp, for this specific result
  - delta which cannot be resolved should:
     - CONF.since: empty array
        - reason: allows not doing `sync` before `bench` in CI
     - CONF.diff: same as no diff
     - `show|remove`: error
  - for relative duration and NUM, base:
     - CONF.since|diff in `show|remove` command: shown result
     - otherwise, latest|now
  - for absolute|relative date: target the closest earlier (not later) result

CONF.since VAL
  - filters result.previous
     - does not impact other deltas resolution (`show|remove`, CONF.diff)
  - VAL is delta, or "" (def, no filtering)
  - same delta as `show|remove` commands
  - result.previous maximum timestamp should be currently shown result's
     - e.g. if `show|remove` command and CONF.since delta starts after `show|remove` delta, result.previous should be empty

Stores:
  - add comment that no support for multiple stores because not very useful and bring questions around data sync
  - add comment that no need to make addResults() concurrent safe. Reasons:
     - append will be concurrent safe on many situations since the number of bytes to write is fairly small
     - unlikely two benchmarks would end exactly at same time on same machine
     - not good practice to execute two benchmarks at same time on same machine
     - can easily fix it by doing a `sync`
  - store.start(storeConfig) -> FUNC(storeConfig)->store instead (closure)
  - always saved at SETTINGS/results.ndjson
  - results use ndjson format. Reasons:
     - JSON parsing much faster than YAML
     - appending a file is much faster than writing the whole file
  - results file vs store:
     - results file logic is not considered a store
        - built-in, not configurable except for file location
        - not loaded like the stores
        - uses functions: addResult(), listResults(), removeResult(), syncResults()
           - result file location is passed as argument (no start())
     - listResults() at the beginning of `bench|show|remove`
        - load full|unfiltered data
     - if CONF.save true:
        - await store.add()
        - if no error, then do addResult()
     - `remove` command:
        - await store.remove()
        - if no error, then do removeResult()
     - `sync` command:
        - store.list()->OBJ_ARR
           - load full|unfiltered data
        - then syncResults(OBJ_ARR)
           - no more store.replace() method

CONF.quiet true:
  - for all commands
  - effect:
     - no console.log()
        - no logs on `exec` command
        - exception: errors are still printed
     - CONF.progress|report forces to empty ARR
  - remove CONF.progress|report "silent"

Reporting on `remove` command:
  - call reporters, like `show`
  - then prompt for removal confirmation
     - unless CONF.force true
  - then print confirmation removal suceeded
     - unless CONF.quiet true

CONF.run-cli.shell:
  - instead of taskFile.shell
  - STR instead of BOOL: "none", "sh", "bash"
  - should default to "none" instead
  - `cli` runner.versions:
     - if "none": none
     - if "bash|sh": { Bash|sh: 'X.Y.Z'}

Plugin shape should be validated:
  - including that plugin properties values cannot be:
     - OBJ
        - reason: nesting does not work well in CLI flags or envvars
     - ARR
        - reason: used for propSets
  - including that plugin properties names must be [a-z][a-z0-9_]*

Error handling:
  - better way for all plugins (report, progress, stores, runners) to signal user error vs bugs
  - better handling of child process errors due to runner bugs (handled as user error right now)
  - plugin|core errors should print message to report GitHub issues to the plugin|core
     - it should include system information

CONF.debug BOOL
  - add debug information, for bug reports
  - add to issue template
  - for all actions
  - print:
     - resolved config
     - task files
     - runner.versions
     - combinations
     - each sample's state (including maxDuration, repeat, etc.)
     - last result, new partialResult, new result
  - do not call reporters

Learn package 'simple-statistics' and use it in spyd???

When killing child process, should kill descendants too
  - e.g. with spyd-runner-cli and command 'yes', 'yes' keeps executing after timeout

Consider lowering the valid Node version for spyd-runner-node, so that `run.node.versions` can target lower versions

Add REPL to evaluate Node.js or `cli` runner task on-the-fly???
  - should allow OPTS.save, so differences are shown

Create a store that works in GitHub actions???

Add progress reporters:
  - spinner with task name and current median
  - progress bar
  - both above (def)

Reporters:
  - types:
     - JSON
     - CLI list
     - CLI table
     - Markdown list
     - Markdown table
     - CLI graphs|histograms
     - CLI where the tasks are in both axis, and the cells are the difference in %
     - CLI with horizontal bars for medians
        - with full CLI width for slowest median
        - still show numbers on top of bars (or on their left side)
        - def reporter instead of simple CLI list, except when there is only one combination
        - for Markdown too???
     - HTML
     - CLI time series (with previous combinations)
  - CLI|Markdown list:
     - follow the formatting I used in fast-cartesian example
        - simple list for TASK with no inputs
  - CLI|Markdown tables:
     - inputs as x axis, tasks as y axis
  - default reporter:
     - CLI|Markdown table if more than half of cells would be filled, and some TASK.inputs are defined
        - CLI|Markdown list otherwise
     - Markdown table|list if CONF.insert '*.md|*.markdown|README|readme'
        - CLI table|list otherwise

Make `precise-now` work on browser + node

Split `precise-timestamp` to own repository
  - make it work on browser + node
  - problem with browser: performance.now() is made only ms-precise by browser due to security timing attacks

Separate into different repos:
  - some plugins are builtin, i.e. required as production dependencies by core
     - including spyd-run-node and spyd-run-cli (until more runners are created)
  - types: spyd-report|progress|run|store-*
  - spyd -> spyd (CLI) + spyd-core (non-CLI)

Clarify features in `README`:
  - most precise and accurate benchmarking
  - pretty reporting
  - comparison with previous results
  - performance testing
  - automatically insert latest results into your documentation
  - custom reporters
  - TypeScript support
  - CI-friendly

Add tests, documentation, etc.:
  - for all repos, including sub-repos
  - add keywords (GitHub, package.json)

Use key-value abstraction layers to add more built-in spyd-store-*

Utilities to help people creating reporters, runners, progress reporters, stores
  - GitHub template
  - test utility

Competitors benchmark:
  - benchmark with other benchmarking tools
  - each should measure Math.random() for the same duration
     - use different durations as inputs
  - report both medians (for accuracy) and standard deviation (for precision)

Add roadmap:
  - point to it from contribution doc to orient contributors towards features I want (e.g. HTML reporter)

Promote

Add other runners:
  - spyd-run-chrome (maybe using puppetter)
  - spyd-run-firefox (maybe using puppetter-firefox)
  - spyd-run-selenium
  - spyd-run-bash
  - spyd-run-go

Commercial offer:
  - reporting dashboard:
     - show time series (i.e. keep history)
        - should not lose history when change only the `title` of the function|variant
     - nice data visualization
     - should show function bodies
  - code editor for tasks files:
     - perform benchmark (inside browser not on our servers)
     - send results to API (like what users would do on CI otherwise)
     - show results from API
     - i.e. can be used like jsperf
  - Sharing like jsperf:
     - allow users to benchmark in their own browsers
  - PR bot
  - notifications
  - user should report results to our API
     - like Codecov does
     - i.e. we do not pay for infrastructure cost, except simple CRUD API to store results
     - should be integrated with CI (i.e. use `ci-info`)
  - pricing:
     - free for open source
     - pay per private repo
