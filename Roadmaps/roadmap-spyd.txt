
        
   SPYD  
        



Fix `exec`
  - e.g. `stdio` must be [`ignore`, `inherit`, `inherit`]
  - pSetTimeout() should be either unref() or clearTimeout(), otherwise it will hold the process
     - take into account that duration might be 0 or 1
  - should show ids, not titles

Fix CLI runner

Fix `src/combinations/main.js` that is currently hardcoded
  - instead of exporting tasks OBJ_ARR, named exports: beforeAll|beforeEach|main|afterEach|afterAll
  - add comment why each task file contains a single task: faster to spawn

Go through whole code, looking for bugs

Precision:
  - compare precision:
     - compare with multiple processes:
        - difference between combinations of single benchmark, vs between single combinations of different benchmarks
        - median vs standard deviation vs variation between processes
        - small CONF.duration vs big CONF.duration
  - note: using a "for loop" without spyd does work:
     - increasing the count makes the results more and more precise
     - the first 2 loops (regardless of the total count) always seem to be different from others
  - check if using a fixed, low amount of processes helps with precision???
  - find ways to improve precision even more???

Live updating:
  - steps:
     - reporter.report()->STR:
        - done after each measures aggregation:
           - counted as part of the `aggregateDuration`
           - unless repeatInit false
              - reason: if repeatInit false, measures will be removed, which would create confusing reporting (e.g. for min|max)
              - other reason: during repeatInit false, stats change a lot, creating flicker
     - do I/O using the last reporter.report() STR
        - done during progress reporting interval function
           - not counted as part of the `aggregateDuration`
  - both steps are:
     - also initially done right after combinations are available, showing no stats yet
     - only done if all of:
        - reporter.progress true (def: false)
        - reportConfig.output "-"
        - CONF.quiet false
  - call reporter.report()->STR with same arguments as the final reporter.report():
     - including result being normalized
     - including having information from initial listResults() (e.g. for previous combinations and diff)
     - including all possible result.combinations, even ones not measured yet
     - excluding CONF.show, always empty
  - if reporter.progress false, reporter.report() can be async. If true, cannot.
  - progress reporter is appended to it:
     - performed right after each live reporting
  - limit the amount of changes of the general shape of the output between the initial call and the final one, to make it look nicer
     - e.g. tables should be initially shown with all rows|columns and empty cells
  - when:
     - ending benchmark: clean progress reporting. Report again (do not keep the last live reporting)
     - stopping benchmark once: clean progress reporting. Report again (do not keep the last live reporting)
     - stopping benchmark twice: clean progress reporting. Keep last live reporting

CONF.concurrency NUM
  - validate that CONF.concurrency NUM is integer >=1
  - each sample spawns NUM processes in parallel
     - in `bench` command, but not in `exec` command
     - start|end group of processes together
     - use same `params`, including `maxLoops`
     - if one process fails
        - the other ones should continue (for cleanup)
        - but the sample should then propagate error
     - measureCost computation should use the same amount of parallel processes
  - add code comment that:
     - CONF.concurrency is meant to measure cost of parallelism
        - both CPU and I/O parallelism
     - if task is I/O bound, it can also improve precision by performing more measures, at the cost of accuracy (due to cost of parallelism)
        - the number where parallel processes start competing for CPU depends on how much duration the task spend on CPU vs I/O
        - above that number:
           - median measure increases much more
           - precision decreases much more
     - move the current code comment from src/measure/combination.js (about spawning processes serially)
  - handle spawn errors due to too many processes at once
     - try to remove process limit with ulimit, and see if another error can happen with a high CONF.concurrency, e.g. too many open files

isAsync:
  - initial check for isAsync:
     - execute func once, without await
     - check if return value is promisable (using p-is-promise)
     - sets func.isAsync BOOL (originally undefined)
     - if isAsync, await return value
  - do the above when func.isAsync undefined && repeat 1
     - add code comment that repeat should always be 1 when func.isAsync undefined, and this probably won't change. It is more of a failsafe.
  - do the above in a `sync_async` dir, next to `sync` and `async` dirs
  - do the above independently for beforeEach, main and afterEach
  - always use await on beforeAll|afterAll, i.e. allow both sync and async
  - remove task.async BOOL

Quantiles|histogram:
  - persist in stores
  - some stats should have a space-efficient shape for stores, but be denormalized on load:
     - histogram:
        - denormalized: OBJ_ARR: low, high, frequency
        - normalized: ARR of [high, frequency]
     - quantiles:
        - denormalized: OBJ_ARR: percentage NUM, value NUM
        - normalized: NUM_ARR
     - both: use difference from median in durations
  - show in `debug` reporter

reporter.debugStats BOOL
  - def: false
  - true for `debug` reporter
  - if false, do not pass:
     - mean
        - add comment that we must ensure median is the main one used, so different reporters are consistent, and also because it is used in sorting combinations, and also it is less precise
     - times
        - add comment that it is a bad indicator of precision, and also might be confused as an indicator of speed due to other benchmark libraries showing it like that
     - minLoopDuration, samples, repeat, loops

Sort all the code comments in `measure`, `sample`, `stats`, `process` and the `node|cli` runners. It's a bit messy right now, and some might be outdated

result.systems:
  - still an OBJ_ARR, one per systemId
  - result.systems[0] -> result.sharedSystem
     - created on results load
     - result.sharedSystem is top-level and not reported (including its title)
  - result.systems[*]:
     - id STR
     - title STR
     - machine: os|memory|cpu
     - versions OBJ
        - all runner.versions shallow merged
        - not versions.RUNNER.VAR: all runners shallow merge their versions OBJ, using CONF.tasks.* order as priority order
        - add comment that meant for software versions, mode (e.g. type of shell) and options
     - git
        - not result.git
     - ci "URL"
        - not OBJ, and not result.ci
     - no more config nor runnerConfig
        - should use variations instead
  - reporting|measuring systems:
     - CONF.system is only for `bench` command, i.e. only one system
     - CONF.include|exclude is only for reporting in `show|remove` commands, i.e. allow reporting several systems
  - add comment that system is only for out-of-spyd env: hardware, OS, git branch, env vars, etc.

plugin.config.PROP STR[_ARR]
  - for all plugins: reporter, progress, runner, store
  - meant for validation, using jest-validate (same validation as for CONF.*):
     - validate against unknown props
        - including automatic suggestion when using wrong case
     - if ARR, use multipleValidOptions()
  - required to use PROP
  - validate PROP matches /^[a-z][a-zA-Z\d]*$/
     - i.e. use - (not _ nor case) as delimiter
  - if STR starts with ./ ../ or /, add to `PATH_CONFIG_PROPS` during config file path resolution

Variations:
  - some config properties can be optionally variable:
     - value PROP: { ID: VAL, ... } instead of VAL
     - PROP: variable property (whole dimension)
     - PROP + ID: variation
  - when merging results:
     - if some PROP uses variations in one result, but not in another
     - then use ID 'default' to convert so all instances of that PROP have a variable property
     - this allows keeping history continuity when introducing variations
  - only on any CONF.* that can change the results:
     - CONF.concurrency
     - CONF.inputs.{inputId}
     - not CONF.duration:
        - no reasons why users would want to measure with different CONF.duration
        - complicates implementation
     - any CONF.runner.{runnerId}.PROP
        - cartesian product only to combinations with that runner
  - each variable property is a separate dimension, distinct from others:
     - in CONF.include|exclude
     - in combination.columnName: several STR
     - result.variations OBJ_ARR_ARR, not OBJ_ARR
     - combination.variations ARR
  - variationId:
     - 'PROP.ID' (not just 'ID')
        - full property name
           - including `inputs.*` and `runnerId.*`
     - used as identifier like for other dimensions, including:
        - comparing between combinations (including between different benchmarks)
        - selecting with CONF.include|exclude|limit
     - no duplicate ID check:
        - reason: namespaces by property name, i.e. not needed
     - should validate ID (not full variationId) allowed characters using the same validation as taskId|systemId|inputId
  - variationTitle: default to same as id
  - variationValue: property VAL
  - set on result.* like other dimensions:
     - for combinations sorting, mean, rank, selection, etc.
     - result.variations OBJ_ARR_ARR: id STR, value VAL, title STR
     - combination.variations OBJ_ARR: id STR, value VAL, title STR
  - just like tasks and inputs, only reported in main reporting table, not in system info below it
  - if several variations have different runner.versions.VAR VAL, they are concatenated as a result.systems[*].versions.VAR ARR
     - printed as a comma-separated list by reporter prettify logic
     - does not mention which variation used which ones. It should be obvious enough from ids or titles
  - multiple inputs dimensions using variations:
     - i.e. CONF.inputs.inputId.ID VAL
     - input dimension is just like any other variation dimension
        - including for cartesian product, CONF.include|exclude|limit
        - variationId is 'inputs.inputId.ID'
           - reasons we do not use shorter 'inputId.ID' instead:
              - forward compatiblity with future variable configuration properties
              - consistent/monomorphic, i.e. simpler to learn
           - like any variationId: no duplicate ID check
           - including with CONF.titles
     - inputId is only part of the variationId
        - used in `inputs` passed to runner.measure()

CONF.*:
  - CONF.info -> CONF.showSystem
  - CONF.context -> CONF.showMetadata
  - pass `undefined` to reporters:
     - if CONF.showSystem false: for result.sharedSystem|systems[*].machine|versions|spyd
     - if CONF.showMetadata false: for result.sharedSystem|systems[*].git|ci and result.timestamp
  - never pass result.id to reporters (not needed)
  - default value:
     - CONF.showSystem: CONF.system !== undefined
     - CONF.showMetadata: command === `show|remove`
  - add comment why we use several BOOL for CONF.show* instead of a single STR_ARR:
     - easier to turn on|off individual values in both CLI flags and CONF.reporterId.show*

CONF.showTitles BOOL
  - if false, show ids, not titles
     - reason: making id clear to users for CONF.include|exclude
  - def: false
  - allow CONF.reportId.showTitles override

Spyd link in reporter
  - should be presented as spyd version instead:
     - "Benchmarked by spyd X.Y.Z (URL to GitHub release)"
  - persist result.spydVersion "X.Y.Z"
     - on load, normalized to results.spyd OBJ:
        - version "X.Y.Z"
        - release "URL" to GitHub release
  - remove CONF.link BOOL
     - instead, make it part of CONF.showSystem BOOL
        - when not present, result.spyd should be undefined
        - should also be undefined when printing to interactive terminal

Variables in `cli` runner:
  - remove user-defined `variables`. Can use either subshells, or command wrapper instead
  - use stdout "pipeInherit":
     - in beforeAll, beforeEach and main
     - only if variable is used by another command
  - validate against using a variable in the wrong command
     - beforeAll: only beforeEach|main|afterEach|afterAll
     - beforeEach: only main|afterEach
     - main: only afterEach
     - afterEach, afterAll: none
     - any other: none
  - available variables (in lowest priority order):
     - {{ENV_VAR}}
        - use process.env as is, i.e. case sensitive on Unix, case insensitive on Windows
     - {{beforeAll}}, {{beforeEach}}, {{main}}
     - {{inputId}}

combination.rowName|columnName:
  - remove dimensions where all combinations have same value:
     - exception: if all dimensions removed, show only task
  - rowName: task, step
  - columnName order is system, runner, input, variation
  - if there are runnerConfig variable properties:
     - must be last
     - empty values (when on different runners) removed
        - i.e. different variable properties for different runners might be aligned together
     - columnName arrays should all have same length, by appending empty strings
        - i.e. if one runner has 1 variable property, and another has 2, the first gets an empty string appended
  - fix combination error task prefix, so it shows all the dimensions
     - except the ones not useful, e.g. system (since there is only one per execution), or inputs if none are used, etc.
  - use in `taskPrefix` used when there is a error during measuring???

Persist result.tasks|systems|runners:
  - only data which cannot be computed: id|title
     - mean|rank should be computed during load normalization instead
  - do not persist result.combinations[*].*Title
     - add those during load normalization instead
     - only persist result.combinations[*].*Id|stats

When identifiers in `include|exclude|limit` do not exist in any combinations:
  - with `bench` command: throw
  - with `show|remove` command: do not throw (i.e. id will never match)
     - reason: identifiers might have changed since previous results (including the last result)

Add `result.diff|slow|slowError|limit` to all results in `result.previous`, not only the target result

Execute `listResults()` earlier:
  - after config retrieval
  - before:
     - `bench` command: combination list computing
     - `show|remove` command: retrieving specific result (i.e. split `getFromStore` into two)
  - reasons:
     - show previous|diff during progress|live reporting
     - fail benchmark fast if problem with store

After listResults(), perform an array of reducing functions:
  - meant for migration, when a new release of spyd is making changes to result properties
  - array is empty for the moment

Sorting:
  - done after listResults()
  - used by:
     - result.previous
     - merging
  - order:
     - based on partialResult.timestamp
     - however, partialResults with same CI build URL (not job) must be consecutive to the earliest of them

New merging logic:
  - bench action:
     - measure|report combinations:
        - from the current partialResult
        - filtered by the current CONF.include|exclude
     - reasons:
        - stronger focus during bench action on the combination being measured
        - remove need during the bench action to have separate CONF.include|exclude for measuring and reporting, which is simpler
           - instead, users should two separate bench then show actions if they want to measure only few combinations then report all of them
  - show|remove actions:
     - report combinations:
        - from the target partialResult
           - any later partialResults are ignored
        - filtered by the current CONF.include|exclude
           - not the CONF.include|exclude from when the partialResult was taken
        - if CONF.include selects combinations present in previous partialResults but absent in target partialResult, merge them:
           - the "latest" combination is used
              - must be before the partialResult was taken
              - "latest" is according to "sorting order" (see above)
              - if none found, silently ignore|skip it
     - reasons:
        - when merging partialResult, cannot know the intended set of combinations since:
           - user might have changed it when the partialResult was measured by passing CONF.tasks|inputs or (if variations) CONF.concurrency|runner.RUNNER.PROP
           - partialResult always has a single CONF.system, and it is hard to know whether previous results' systems have been now removed or not
        - so the user must specify explicitely which additional dimensions are intended to be reported
        - only merging explicitly gives predictable results users would expect
        - makes more sense for time series reporters
     - when several combinations have different:
        - timestamp: keep earliest
        - spydVersion: keep the lowest one
        - CI build|job:
           - merge:
              - if one has no CI build|job URL, use other
              - if same CI job URL, use it
              - if same CI build URL, use it
              - if several CI build URLs, use the new one
           - reason: benchmark parallelized on several machines
  - remove CONF.merge

store.add(result) -> store.add(partialResult)
  - i.e. append only, not merged with previous ones
  - same for addResult()

Deltas:
  - in `show|remove` commands, and CONF.since|diff
  - computed by core
  - can be:
     - absolute timestamp
     - relative duration like "3m"
     - NUM
  - operates on partialResults, not results
     - after CONF.include|exclude filtering
  - delta which cannot be resolved should:
     - CONF.since: empty array
        - reason: allows not doing `sync` before `bench` in CI
     - CONF.diff: same as no diff
     - `show|remove`: error
  - for relative duration and NUM, base:
     - CONF.since|diff in `show|remove` command: shown result
     - otherwise, latest|now
  - for absolute|relative date: target the closest earlier (not later) result

CONF.since VAL
  - filters result.previous
     - does not impact other deltas resolution (`show|remove`, CONF.diff)
  - VAL is delta, or "" (def, no filtering)
  - same delta as `show|remove` commands
  - result.previous maximum timestamp should be currently shown result's
     - e.g. if `show|remove` command and CONF.since delta starts after `show|remove` delta, result.previous should be empty

Stores:
  - add comment that no support for multiple stores because not very useful and bring questions around data sync
  - add comment that no need to make addResults() concurrent safe. Reasons:
     - append will be concurrent safe on many situations since the number of bytes to write is fairly small
     - unlikely two benchmarks would end exactly at same time on same machine
     - not good practice to execute two benchmarks at same time on same machine
     - can easily fix it by doing a `sync`
  - store.start(storeConfig) -> FUNC(storeConfig)->store instead (closure)
  - always saved at SETTINGS/history.ndjson
  - results use ndjson format. Reasons:
     - JSON parsing much faster than YAML
     - appending a file is much faster than writing the whole file
  - results file vs store:
     - results file logic is not considered a store
        - built-in, not configurable except for file location
        - not loaded like the stores
        - uses functions: addResult(), listResults(), removeResult(), syncResults()
           - result file location is passed as argument (no start())
     - listResults() at the beginning of `bench|show|remove`
        - load full|unfiltered data
     - if CONF.save true:
        - await store.add()
        - if no error, then do addResult()
     - `remove` command:
        - await store.remove()
        - if no error, then do removeResult()
     - `sync` command:
        - store.list()->OBJ_ARR
           - load full|unfiltered data
        - then syncResults(OBJ_ARR)
           - no more store.replace() method

Reporting on `remove` command:
  - call reporters, like `show`
     - i.e. must accept same CONF.*, e.g. CONF.tasks|system
  - then prompt for removal confirmation
     - unless CONF.force true
  - do not print that confirmation removal suceeded (but print error if failed)

CONF.run-cli.shell:
  - instead of taskFile.shell
  - STR instead of BOOL: "none", "sh", "bash"
  - should default to "none" instead
  - `cli` runner.versions:
     - if "none": none
     - if "bash|sh": { Bash|sh: 'X.Y.Z'}

Plugin shape should be validated

Error handling:
  - better way for all plugins (report, progress, stores, runners) to signal user error vs bugs
  - better handling of child process errors due to runner bugs (handled as user error right now)
  - plugin|core errors should print message to report GitHub issues to the plugin|core
     - it should include system information

CONF.debug BOOL
  - add debug information, for bug reports
  - add to issue template
  - for all actions
  - print:
     - resolved config
     - task files
     - runner.versions
     - combinations
     - each sample's state (including maxDuration, repeat, etc.)
     - last result, new partialResult, new result
  - do not call reporters

Learn package 'simple-statistics' and use it in spyd???

When killing child process, should kill descendants too
  - e.g. with spyd-runner-cli and command 'yes', 'yes' keeps executing after timeout

Consider lowering the valid Node version for spyd-runner-node, so that `run.node.versions` can target lower versions

Add REPL to evaluate Node.js or `cli` runner task on-the-fly???
  - should allow OPTS.save, so differences are shown

Create a store that works in GitHub actions???

Add progress reporters:
  - spinner with task name and current median
  - progress bar
  - both above (def)

Reporters:
  - types:
     - JSON
     - CLI list
     - CLI table
     - Markdown list
     - Markdown table
     - CLI graphs|histograms
     - CLI where the tasks are in both axis, and the cells are the difference in %
     - CLI with horizontal bars for medians
        - with full CLI width for slowest median
        - still show numbers on top of bars (or on their left side)
        - def reporter instead of simple CLI list, except when there is only one combination
        - for Markdown too???
     - HTML
     - CLI time series (with previous combinations)
  - CLI|Markdown list:
     - follow the formatting I used in fast-cartesian example
        - simple list for TASK with no inputs
  - CLI|Markdown tables:
     - inputs as x axis, tasks as y axis
  - default reporter:
     - CLI|Markdown table if more than half of cells would be filled, and some inputs are defined
        - CLI|Markdown list otherwise
     - Markdown table|list if CONF.insert '*.md|*.markdown|README|readme'
        - CLI table|list otherwise

Make `precise-now` work on browser + node

Split `precise-timestamp` to own repository
  - make it work on browser + node
  - problem with browser: performance.now() is made only ms-precise by browser due to security timing attacks

Separate into different repos:
  - some plugins are builtin, i.e. required as production dependencies by core
     - including spyd-run-node and spyd-run-cli (until more runners are created)
  - types: spyd-reporter|progress|runner|store-*
  - spyd -> spyd (CLI) + spyd-core (non-CLI)

Clarify features in `README`:
  - most precise and accurate benchmarking
  - pretty reporting
  - history
  - performance testing
  - automatically insert latest results into your documentation
  - custom reporters
  - TypeScript support
  - CI-friendly

Add tests, documentation, etc.:
  - for all repos, including sub-repos
  - add keywords (GitHub, package.json)

Use key-value abstraction layers to add more built-in spyd-store-*

Utilities to help people creating reporters, runners, progress reporters, stores
  - GitHub template
  - test utility

Competitors benchmark:
  - benchmark with other benchmarking tools
  - each should measure Math.random() for the same duration
     - use different durations as inputs
  - report both medians (for accuracy) and standard deviation (for precision)

Add roadmap:
  - point to it from contribution doc to orient contributors towards features I want (e.g. HTML reporter)

Send PRs to do or redo benchmarks of repositories to
  - get user feedback
  - experience the library as a user
  - get visibility

Promote

Add other runners:
  - spyd-runner-chrome (maybe using puppetter)
  - spyd-runner-firefox (maybe using puppetter-firefox)
  - spyd-runner-selenium
  - spyd-runner-bash
  - spyd-runner-go

Commercial offer:
  - reporting dashboard:
     - show time series (i.e. keep history)
        - should not lose history when change only the `title` of the function|variant
     - nice data visualization
     - should show function bodies
  - code editor for tasks files:
     - perform benchmark (inside browser not on our servers)
     - send results to API (like what users would do on CI otherwise)
     - show results from API
     - i.e. can be used like jsperf
  - Sharing like jsperf:
     - allow users to benchmark in their own browsers
  - PR bot
  - notifications
  - user should report results to our API
     - like Codecov does
     - i.e. we do not pay for infrastructure cost, except simple CRUD API to store results
     - should be integrated with CI (i.e. use `ci-info`)
  - pricing:
     - free for open source
     - pay per private repo
