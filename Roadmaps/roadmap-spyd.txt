
        
   SPYD  
        



Percentiles|histogram:
  - use difference from median in durations in histogram and percentiles
  - persist in stores
  - show in `debug` reporter???

Rename:
  - benchmark is the whole setup:
     - task files: tasks + inputs
        - benchmark file -> task file
     - system
     - config
  - run: calling `spyd run` once
  - iteration -> combination
  - saved benchmark -> result
  - rawBenchmark -> partialResult

OPTS.report|run|store|progress:
  - OPTS.report|run|store|progress 'NAME'_ARR (enable|disable)
  - OPTS.report|run|store|progress-NAME-OPT VAL (options)
     - can set options even if disabled. Does not enable
  - reasons:
     - flat simpler than nesting
     - single delimiter character. No mixing several like - _ .
     - distinction selecting adapters vs configuring them
     - allow different users and programming languages to use preferes characters in ids
     - CLI flag friendly since starts with --
     - works unescaped with YAML and JSON
     - easy to understand when both OPTS.OPT and OPTS.system-{systemId}-OPT are possible. The second is just like a selector/namespace
  - remove the `addRunners()` function which split OPTS.run to OPTS.run|runners

ID validation:
  - for user-defined (task|input|system|mergeId):
     - [[a-zA-Z0-9]._-]+
     - no empty string
     - for both system.id and system.value
  - for plugins (report|run|store|progress):
     - [a-z][a-z0-9-]*
     - no empty string
     - force module name to spyd-report|run|store|progress-NAME

Def value for tasks file:
  - should be ./[../[...]]benchmark/tasks.*
      - benchmarks -> benchmark
      - looked in current or any parent directory

result.systems shape
  - still an OBJ_ARR, one per systemId
  - result.systems[0] -> result.sharedSystem
     - created on results load
  - result.systems[*]:
     - id STR
     - title STR
     - machine: os|memory|cpu
     - opts: duration
     - run (runner system variables)
     - git (not result.git)
     - ci "URL" (not OBJ, and not result.ci)

OPTS.info|context -> OPTS.show STR_ARR among 'system', 'metadata'
  - if no:
     - 'system': pass `undefined` to reporters for result.sharedSystem|systems[*].machine|opts|run
     - 'metadata': pass `undefined` to reporters for result.sharedSystem|systems[*].git|ci and result.id|timestamp
  - default value:
     - has "system" if OPTS.system defined
     - has "metadata" if `show|remove` command

runner.commands(runOpts):
  - rename to runner.run(...)
  - arguments (eventName, runOpts):
     - split main entry file to 3 (load/run/debug), so that requiring the file is faster
  - OPTS.run.node.versions -> OPTS.run.node.version (only one version)
  - return a single OBJ instead of OBJ_ARR:
     - should use systems instead to run several runOpts
     - commands is not a input-like dimension anymore, including in:
        - combination.name|columnName
        - combination.commandRank
        - combination.previous
        - combinations sorting
        - duplication removal
        - commandId in OPTS.limit
        - `show`/`remove` command filtering
        - result.commands[Pretty]
     - returned OBJ properties:
        - spawn ['FILE', 'ARG',...]
        - spawnOptions OBJ (def: {})
        - not needed anymore:
           - id -> not needed anymore since no more targetting
           - title|description -> runner.id|title + runner.system
  - remove any instances of the word "command", except for CLI commands, to avoid confusion
     - commandOpts -> runOpts

Instead of runner.system:
  - runner.run(eventName, runOpts)->OBJ with OBJ.system OBJ_ARR (def: []):
     - id STR
     - title STR
     - value STR
        - no more STR_ARR to let core execute command. Runners must provide direct value themselves instead.
     - description STR
     - version BOOL (def: false). If true:
        - value must contain X.Y.Z
        - expand OBJ to 3 OBJs instead:
           - id is suffixed with _major|minor|patch
           - value X[.Y[.Z]]
           - same title|description
  - OPTS.system STR can use {{VAR}}
     - VAR is system.id
     - subtituted by system.value
  - result.system.run.VAR STR
     - VAR is system.title
     - STR is system.description
  - with `node` runner:
     - if no OPTS.run-node.version: id "node", title "Node.js", value "X.Y.Z" (using process.version), description "X.Y.Z"
     - if OPTS.run-node.version: same but using nvexeca()

Variables:
  - in `cli` runner:
     - remove user-defined `variables`. Can use either subshells, or command wrapper instead
     - `ignore` command stdout unless a variable is being used, or in debug mode
     - add {{main}} variable (like {{before}})
  - use same logic for both OPTS.system and `cli` runner
  - variable case:
     - ENV_VAR: use process.env as is, i.e. case sensitive on Unix, case insensitive on Windows
     - others:
        - case sensitive
        - lowercase (unless user-defined)
  - available variables (in lowest priority order):
     - OPTS.system:
        - {{ENV_VAR}}
        - {{os}} {{os_full}}
        - runner-specific variable, e.g. {{node_major_version}}
     - `cli` runner:
        - {{ENV_VAR}}
        - {{before}}, {{main}}
        - {{inputId}}

Persist result.tasks|inputs|systems|commands:
  - only data which cannot be computed: id|title|description
     - mean|rank should be computed during load normalization instead
  - do not persist result.combinations[*].*Title|Description
     - add those during load normalization instead
     - only persist result.combinations[*].*Id|stats

Run `listResults()` earlier:
  - after options retrieval
  - before:
     - `run` command: combination list computing
     - `show|remove` command: retrieving specific result (i.e. split `getFromStore` into two)
  - reasons:
     - with OPTS.merge, allows skipping already saved combinations
        - including when continuing previously interrupted run
     - show previous|diff during progress|live reporting
     - fail run fast if problem with store

After listResults(), core should normalize partialResults to results:
  - perform an array of reducing functions:
     - meant for migration, when a new release of spyd is making changes to result properties
     - array is empty for the moment
  - filter by tasks|inputs|systems
  - sort by partialResult.timestamp
  - group partialResults to result using partialResult.mergeId
     - partialResult.id -> not kept in result
     - partialResult.mergeId -> result.id
  - silently filter out duplicate combinations (same mergeId+taskId+inputId+systemId)
     - reason: might happen if two results with same mergeId ran in parallel
     - keep one with earliest timestamp

store.add(result) -> store.add(partialResult)
  - i.e. append only, not merged with previous ones
  - same for addResult()

Add in comment and --help that OPTS.merge is meant only for doing a single run but incrementally:
  - parallelize run across identical machines (including in CI): same mergeId, same systemId
  - run across different machines|hardware|software (including in CI): same mergeId, different systemId
  - continue previously interrupted long run

When merging combination and there is a duplicate of same mergeId and taskId+inputId+systemId:
  - different os|cpu|memory|git|runnerOpts|duration:
     - throw and suggest to either use a different systemId, or make a different run
     - reason: merge is meant for incremental runs, i.e. combinations must be comparable
  - different CI build|job:
     - merge:
        - if one has no CI build|job URL, use other
        - if same CI job URL, use it
        - if same CI build URL, use it
        - if several CI build URLs, use the new one
     - reason: run parallelized on several machines
  - different timestamp: keep earliest
  - no difference check if different systemId
     - only appends to result.systems
     - reasons: using systems to compare machines, spyd|runner options, git branches

OPTS.merge skipping previous combinations:
  - if OPTS.merge in `run` command, do not run (but still report) combinations already saved
  - reason: OPTS.merge is meant for incremental runs, including continuing interrupted run

Long run interruption:
  - if all of:
     - user interactive interruption: `SIGINT`, `SIGBREAK`, `SIGHUP`
     - interactive TTY
     - OPTS.save true
     - at least one combination completed
  - then prompts whether want to save partial result
  - if so:
     - save partial result
     - print the CLI flag to continue partial result, i.e. --merge=MERGE_ID
  - remove OPTS.merge "" to mean "same|last result"

Allow comparing different systems in a single run:
  - OPTS.system "systemId"[_ARR]
     - id not title, i.e. no slugification
     - if several, creates several combinations in current run
     - def: ['default'] (title "Default system")
     - used to target results in `show|remove` commands too
  - OPTS.system-{systemId}-OPT:
     - title STR (def: "systemId")
     - runner-{runnerId}-OPT
     - duration
     - parsing needs to take into account that systemId might have a "-"

Deltas:
  - in `show|remove` commands, and OPTS.since|diff
  - computed by core
  - based on listResults() output, after tasks|inputs|systems filtering
     - reason: if a user is doing `run` always filtered for specific tasks|inputs|systems, without using OPTS.merge (e.g. each task is a library, and is only recomputed on a new version of the library), then `show` or default OPTS.diff 1 should compare each combination to the latest which was run with same taskId|inputId|systemId
        - should document this, since it is an alternative to OPTS.merge, with similar goals for benchmarks slow or with many dimensions
  - can be:
     - absolute timestamp
     - relative duration like "3m"
     - NUM
     - mergeId
  - operates on results, not on partialResults
  - when using timestamps|duration, should retrieve the full result
     - even if some partialResult are before, some after the timestamp, for this specific result
  - delta which cannot be resolved should:
     - OPTS.since: empty array
        - reason: allows not doing `sync` before `run` in CI
    - OPTS.diff: same as no diff
    - `show|remove`: error
  - for relative duration and NUM, base:
    - OPTS.since|diff in `show|remove` command: shown result
    - otherwise, latest|now
  - for absolute|relative date: target the closest earlier (not later) result

OPTS.since VAL
  - filters result.previous
     - does not impact other deltas resolution (`show|remove`, OPTS.diff)
  - VAL is delta, or "" (def, no filtering)
  - same delta as `show|remove` commands
  - result.previous maximum timestamp should be currently shown result's
     - e.g. if `show|remove` command and OPTS.since delta starts after `show|remove` delta, result.previous should be empty

Stores:
  - add comment that no support for multiple stores because not very useful and bring questions around data sync
  - add comment that no need to make addResults() concurrent safe. Reasons:
     - append will be concurrent safe on many situations since the number of bytes to write is fairly small
     - unlikely two runs would end exactly at same time on same machine
     - not good practice to run two runs at same time on same machine
     - can easily fix it by doing a `sync`
  - store.start(OPTS) -> FUNC(OPTS)->store instead (closure)
  - OPTS.results "PATH"
     - def: ./[../[...]]benchmark/results.ndjson
     - error if PATH does not end with ".ndjson"
     - results use ndjson format. Reasons:
        - JSON parsing much faster than YAML
        - appending a file is much faster than writing the whole file
  - results file vs store:
     - results file logic is not considered a store
        - built-in, not configurable except for file location
        - not loaded like the stores
        - uses functions: addResult(), listResults(), removeResult(), syncResults()
           - result file location is passed as argument (no start())
     - listResults() at the beginning of `run|show|remove`
        - load full|unfiltered data
     - if OPTS.save true:
        - await store.add()
        - if no error, then do addResult()
     - `remove` command:
        - await store.remove()
        - if no error, then do removeResult()
     - `sync` command:
        - store.list()->OBJ_ARR
           - load full|unfiltered data
        - then syncResults(OBJ_ARR)
           - no more store.replace() method

OPTS.quiet true:
  - for all commands
  - effect:
     - no console.log()
        - no logs on `debug` command
        - exception: errors are still printed
     - OPTS.progress|report forces to empty ARR
  - remove OPTS.progress|report "silent"

Reporting on `remove` command:
  - call reporters, like `show`
  - then prompt for removal confirmation
     - unless OPTS.force true
  - then print confirmation removal suceeded
     - unless OPTS.quiet true

Reporter live updating:
  - do all of this in a feature branch to ensure this does not skew measurements
     - compare Math.random() benchmark with|without it
  - screen refreshing:
     - refresh whole screen at the beginning|end
        - use `signal-exit`
        - experiment if there is a way to refresh partial screen instead of whole screen
           - it should still work if user types newline or characters
     - each update should refresh the whole screen with the new content
        - but by printing over it, not clearing it first, to avoid flickering
        - i.e. need to padRight() the new content if the old content was larger
  - new progress.*() shape:
     - since core now handles refreshing the screen
     - progress.update():
        - must return a STR
        - must be sync
     - remove progress.start|stop()
  - compute reporter.report()->STR after each child process completion
     - only if all of:
        - reporter.progress true (def: false)
        - reporterOpts.output "-"
        - OPTS.quiet false
     - set result.combinations[*].running BOOL
        - `debug` reporter should highlight running combination
     - called with same arguments as the final reporter.report():
        - including result being normalized
        - including having information from initial listResults() (e.g. for previous combinations and diff)
        - including all possible result.combinations, even ones not run yet
        - excluding OPTS.show, always empty
     - limit the amount of changes of the general shape of the output between the initial call and the final one, to make it look nicer
        - e.g. tables should be initially shown with all rows|columns and empty cells
  - on each progress update, prepend last reporter.report()->STR, from each such reporter
  - if reporter.progress false, reporter.report() can be async. If true, cannot.

Named exports in task files:
  - instead of exporting `tasks` array of objects, export each object individually
     - for `cli` runner, means top-level property of YAML whole file, which is a plain object
  - export name is the default value for `task.id`, which can be overridden
  - some known properties (`inputs` and `shell`) are also exported. Users can still use those words as task `id` by specifying them as `task.id` explicitely
  - both in `node` and `cli` runners

Shortcut notation in task files:
  - instead of a plain object, if only property is `main`, can use:
     - `node` runner: function
     - `cli` runner: string

OPTS.run-cli.shell:
  - instead of taskFile.shell
  - STR instead of BOOL: "none", "sh", "bash"
  - should default to "none" instead
  - `cli` runner system variables:
     - if "none": none
     - if "bash": id "shell", title "Shell", value "bash_X_Y_Z", description "Bash X.Y.Z"
     - if "sh": id "shell", title "Shell", value "sh_X_Y_Z", description "sh X.Y.Z"

Error handling:
  - better way for all plugins (report, progress, stores, runners) to signal user error vs bugs
  - better handling of child process errors due to runner bugs (handled as user error right now)
  - plugin|core errors should print message to report GitHub issues to the plugin|core
     - it should include system information

Learn package 'simple-statistics' and use it in spyd

Use a `config` library instead of using our own logic???

When killing child process, should kill descendants too
  - e.g. with spyd-runner-cli and command 'yes', 'yes' keeps running after timeout

Consider lowering the valid Node version for spyd-runner-node, so that `run.node.versions` can target lower versions

Create a store that works in GitHub actions???

Add progress reporters:
  - spinner with task name and current median
  - progress bar
  - both above (def)

Reporters:
  - types:
     - JSON
     - CLI list
     - CLI table
     - Markdown list
     - Markdown table
     - CLI graphs|histograms
     - CLI where the tasks are in both axis, and the cells are the difference in %
     - CLI with horizontal bars for medians
        - with full CLI width for slowest median
        - still show numbers on top of bars (or on their left side)
        - def reporter instead of simple CLI list, except when there is only one combination
        - for Markdown too???
     - HTML
     - CLI time series (with previous combinations)
  - CLI|Markdown list:
     - follow the formatting I used in fast-cartesian example
        - simple list for TASK with no inputs
  - CLI|Markdown tables:
     - inputs as x axis, tasks as y axis
  - default reporter:
     - CLI|Markdown table if more than half of cells would be filled, and some TASK.inputs are defined
        - CLI|Markdown list otherwise
     - Markdown table|list if OPTS.insert '*.md|*.markdown|README|readme'
        - CLI table|list otherwise

Separate into different repos:
  - some plugins are builtin, i.e. required as production dependencies by core
     - including spyd-run-node and spyd-run-cli (until more runners are created)
  - types: spyd-report|progress|run|store-*
  - spyd -> spyd (CLI) + spyd-core (non-CLI)

Clarify features in `README`:
  - most precise and accurate benchmarking
  - pretty reporting
  - comparison with previous benchmarks
  - performance testing
  - automatically insert latest benchmarks into your documentation
  - custom reporters
  - TypeScript support
  - CI-friendly

Add tests, documentation, etc.:
  - for all repos, including sub-repos
  - add keywords (GitHub, package.json)

Use key-value abstraction layers to add more built-in spyd-store-*

Utilities to help people creating reporters, runners, progress reporters, stores
  - GitHub template
  - test utility

Competitors benchmark:
  - benchmark with other benchmarking tools
  - each should benchmark Math.random() for the same duration
     - use different durations as inputs
  - report both medians (for accuracy) and standard deviation (for precision)

Add roadmap:
  - point to it from contribution doc to orient contributors towards features I want (e.g. HTML reporter)

Promote

Add other runners:
  - spyd-run-chrome (maybe using puppetter)
  - spyd-run-firefox (maybe using puppetter-firefox)
  - spyd-run-selenium
  - spyd-run-bash
  - spyd-run-go

Commercial offer:
  - reporting dashboard:
     - show time series (i.e. keep history)
        - should not lose history when change only the `title` of the function|variant
     - nice data visualization
     - should show function bodies
  - code editor for benchmark files:
     - run benchmarks (inside browser not on our servers)
     - send benchmark results to API (like what users would do on CI otherwise)
     - show results from API
     - i.e. can be used like jsperf
  - Sharing like jsperf:
     - allow users to run in their own browsers
  - PR bot
  - notifications
  - user should report benchmark results to our API
     - like Codecov does
     - i.e. we do not pay for infrastructure cost, except simple CRUD API to store benchmark results
     - should be integrated with CI (i.e. use `ci-info`)
  - pricing:
     - free for open source
     - pay per private repo
