
        
   SPYD  
        



Incremental accurate stats:
  - sort measures incrementally, after each process
     - childMeasures.sort()
     - then merge sort with measures
        - check if doing in-place is faster
        - consider using ARR.copyWithin()
  - no more need for processMedians array: can compute median directly instead
  - compute stats incrementally, after each process
     - sum
        - keep a single total sum float
        - subtract current sum of last 15% to it
     - only median for:
        - repeatCost|measureCost processGroup
        - main processGroup without live reporting
     - reason: spreads slowdown through the combination instead of only at end, so user cannot perceive it during live reporting
     - other reason: makes processGroup real duration closer to expected one
  - loadCost should also use incremental sort
     - then use normal median, not `getUnsortedMedian()`
  - check how the time required after process increases linearly, and see if there is any way to improve it

Quantiles|histogram:
  - use difference from median in durations in histogram and quantiles
     - only to lower storage cost
     - on pre-save normalization
     - undone on post-load normalization
  - persist in stores
  - show in `debug` reporter
  - first remove the bottom|top 5% quantiles?

New processGroups logic
  - rename processGroups to samples
  - split processGroup main function into:
     - an inner function, receiving state, spawnin process, computing new state and returning it
     - an outer function, passing state around and deciding which processGroup's inner function to call next, and computing how much time left

reportCost|measureCost progressive computation:
  - measure all processGroups concurrently: main one, repeatCost, measureCost
     - concurrent, but still one at a time
     - the processGroup with lowest processGroupDuration spent always executes next
        - exception: if last had repeatInit true, execute it again
           - unless out of processGroupDuration
           - i.e. do not switch to other progressGroup
     - if same processGroupDuration spent (including 0), priority is: measureCost > repeatCost > main
     - reason: not to block live reporting at the beginning of the benchmark and between each combination
  - repeatCost|measureCost gets 10% of combinationDuration, main gets 80%
     - i.e. after 30% of combinationDuration, only main is left executing
  - add comment that first 12.5% of main processGroup will have more imprecise repeatCost|measureCost when normalizing measures and computing repeat|maxDuration, but that's fine
  - the `timeResolution` should be recomputed after each measureCost sample, but the `Math.min()` of it should be used

Delay repeatCost measuring:
  - at beginning, repeatCost is not measured and has 0 processGroupDuration
     - main processGroup gets additional 10% processGroupDuration
     - repeatCost is 0
  - after first sample of main processGroup completes, if its repeatInit is still true:
     - before executing main processGroup again, measure repeatCost processGroup until either:
        - its repeatInit becomes true
        - it is out of processGroupDuration
     - then finish executing main processGroup until its repeatInit becomes true (or it is out of processGroupDuration)

Measure combinations concurrently
  - concurrently, but still one at a time, using same sample orchestration logic as the one used to orchestrate repeatCost|measureCost|main samples
  - reason: better live reporting
  - other reason: provides with fast fail if one combination times out or throw exception
  - if two combinations have same combinationDuration left, pick a random one
     - reason: random tasks progressing is more visually interesting than sequential
  - when completing initial measureCost sample, do the first main sample after it in order to provide with fast first reporting of each combination
  - progress reporter should not show current combination nor counter anymore
  - progress reporter durationLeft and percentage need to take into account that multiple combinations are measured concurrently

Improve precision:
  - find ways to improve precision even more???
  - find ways to improve precision if CONF.duration is very low???
  - tweak outliers removal:
     - find the best threshold value
     - remove outliers on both slow and fast ends???

Reporter live updating:
  - do all of this in a feature branch to ensure this does not skew measurements
     - compare Math.random() duration with|without it
  - screen refreshing:
     - refresh whole screen at the beginning|end
        - use `signal-exit`
        - experiment if there is a way to refresh partial screen instead of whole screen
           - it should still work if user types newline or characters
     - each update should refresh the whole screen with the new content
        - but by printing over it, not clearing it first, to avoid flickering
        - i.e. need to padRight() the new content if the old content was larger
  - new progress.*() shape:
     - since core now handles refreshing the screen
     - progress.update():
        - must return a STR
        - must be sync
     - remove progress.start|stop()
  - compute reporter.report()->STR after each sample completion
     - if CONF.parallel, after whole group of processes completed
     - only if all of:
        - reporter.progress true (def: false)
        - reportConfig.output "-"
        - CONF.quiet false
     - if sample has repeatInit true, do not live report it yet
     - called with same arguments as the final reporter.report():
        - including result being normalized
        - including having information from initial listResults() (e.g. for previous combinations and diff)
        - including all possible result.combinations, even ones not measured yet
        - excluding CONF.show, always empty
     - limit the amount of changes of the general shape of the output between the initial call and the final one, to make it look nicer
        - e.g. tables should be initially shown with all rows|columns and empty cells
  - on each progress update, prepend last reporter.report()->STR, from each such reporter
  - if reporter.progress false, reporter.report() can be async. If true, cannot.
  - live reporting + progress reporting should happen in a worker thread
     - reason: not blocking the CPU so measuring can happen concurrently
     - happens at regular interval
     - each time a runner process completes, parent process computes new stats, orchestrator sends it to worker thread
        - worker thread updates its state but still wait for next refresh frame to report it

Infinite duration:
  - CONF.duration 0
  - default value for CONF.duration if interactive TTY
     - default value still 10 if not iteractive TTY
  - measures forever
  - stopping:
     - on `SIGINT`, `SIGBREAK`, `SIGHUP` or SIGTERM
        - either interactive TTY or not
     - keep both progress reporter and live reporter printed
     - report all other reporters too
  - progress reporter:
     - pass percentage undefined
     - instead of durationLeft, pass just duration
        - incrementing, not decrementing
        - time units increase too: SSs, then MMmSSs, then HHhMMmSSs
  - reportCost|measureCost:
     - instead of spending first 10% duration concurrently with main processGroup, orchestrator gives their duration a weight 0.1 when comparing with other progressGroups
     - i.e. measured 10 times less than main processGroups in average
  - not allowed if CONF.save true
  - no timing during measuring:
     - no process timeout
     - no `measureDurationLeft` in `maxDuration`
     - orchestrator does not check for processGroupEnd

Parallel:
  - CONF.parallel NUM
     - validate that CONF.parallel NUM is integer >1
  - spawns NUM processes in parallel
     - in `bench` command, but not in `exec` command
     - start|end group of processes together
        - i.e. spawns only the process execution logic in parallel, not the whole performRun()
     - use same maxDuration and timeoutNs
     - if one process fails, the other ones should be terminated
     - measureCost|repeatCost computation should use the same amount of parallel processes
  - add code comment that:
     - CONF.parallel is meant to measure cost of parallelism
        - both CPU and I/O parallelism
     - if task is I/O bound, it can also improve precision by performing more measures, at the cost of accuracy (due to cost of parallelism)
        - the number where parallel processes start competing for CPU depends on how much duration the task spend on CPU vs I/O
        - above that number:
           - median measure increases much more
           - precision decreases much more
     - move the current code comment from src/measure/combination.js
  - handle spawn errors due to too many processes at once
     - try to remove process limit with ulimit, and see if another error can happen with a high CONF.parallel, e.g. too many open files
  - part of system
     - result.systems[*].config.parallel
     - if result.sharedSystem.config.parallel 1, removed instead so it does not show up
     - when merging partialResults, CONF.parallel should behave like CONF.duration, i.e. not allow merging with different values

Sort all the code comments in `measure/**` and the `node|cli` runners. It's a bit messy right now, and some might be outdated

CONF.report|run|store|progress:
  - CONF.report|run|store|progress 'NAME'_ARR (enable|disable)
  - CONF.report|run|store|progress-NAME-VAR VAL (config)
     - can set config even if disabled. Does not enable
  - reasons:
     - flat simpler than nesting
     - single delimiter character. No mixing several like - _ .
     - distinction selecting adapters vs configuring them
     - allow different users and programming languages to use preferes characters in ids
     - CLI flag friendly since starts with --
     - works unescaped with YAML and JSON
     - easy to understand when both CONF.VAR and CONF.system-{systemId}-VAR are possible. The second is just like a selector/namespace
  - remove the `addRunners()` function which split CONF.run to CONF.run|runners

ID validation:
  - for user-defined (task|input|system|mergeId):
     - [[a-zA-Z0-9]._-]+
     - no empty string
     - for both system.id and system.value
  - for plugins (report|run|store|progress):
     - [a-z][a-z0-9-]*
     - no empty string
     - force module name to spyd-report|run|store|progress-NAME
  - default mergeId in CI:
     - use a more generic characters replacement logic, with a slugify library, using the list of allowed characters in mergeId

result.systems shape
  - still an OBJ_ARR, one per systemId
  - result.systems[0] -> result.sharedSystem
     - created on results load
  - result.systems[*]:
     - id STR
     - title STR
     - machine: os|memory|cpu
     - config: duration|parallel
     - run (runner system variables)
     - git (not result.git)
     - ci "URL" (not OBJ, and not result.ci)

CONF.info|context -> CONF.show STR_ARR among 'system', 'metadata'
  - if no:
     - 'system': pass `undefined` to reporters for result.sharedSystem|systems[*].machine|config|run
     - 'metadata': pass `undefined` to reporters for result.sharedSystem|systems[*].git|ci and result.id|timestamp
  - default value:
     - has "system" if CONF.system defined
     - has "metadata" if `show|remove` command

runner.commands(runConfig):
  - rename to runner.launch(...)
  - arguments (eventName, runConfig):
     - split main entry file to 2 (load|run), so that requiring the file is faster
  - CONF.run.node.versions -> CONF.run.node.version (only one version)
  - return a single OBJ instead of OBJ_ARR:
     - should use systems instead to perform several runConfig
     - commands is not a input-like dimension anymore, including in:
        - combination.name|columnName
        - combination.commandRank
        - combination.previous
        - combinations sorting
        - duplication removal
        - commandId in CONF.limit
        - `show`/`remove` command filtering
        - result.commands[Pretty]
     - returned OBJ properties:
        - spawn ['FILE', 'ARG',...]
        - spawnOptions OBJ (def: {})
        - not needed anymore:
           - id -> not needed anymore since no more targetting
           - title|description -> runner.id|title + runner.system
  - remove any instances of the word "command", except for CLI commands, to avoid confusion
     - commandConfig -> runConfig

Instead of runner.system:
  - runner.run(eventName, runConfig)->OBJ with OBJ.system OBJ_ARR (def: []):
     - id STR
     - title STR
     - value STR
        - no more STR_ARR to let core execute command. Runners must provide direct value themselves instead.
     - description STR
     - version BOOL (def: false). If true:
        - value must contain X.Y.Z
        - expand OBJ to 3 OBJs instead:
           - id is suffixed with _major|minor|patch
           - value X[.Y[.Z]]
           - same title|description
  - CONF.system STR can use {{VAR}}
     - VAR is system.id
     - subtituted by system.value
  - result.system.run.VAR STR
     - VAR is system.title
     - STR is system.description
  - with `node` runner:
     - if no CONF.run-node.version: id "node", title "Node.js", value "X.Y.Z" (using process.version), description "X.Y.Z"
     - if CONF.run-node.version: same but using nvexeca()

Variables:
  - in `cli` runner:
     - remove user-defined `variables`. Can use either subshells, or command wrapper instead
     - add code comment that {{main}} is purposely not provided so users only put what they want to measure in main, not cleanup code for "after"
  - use same logic for both CONF.system and `cli` runner
  - variable case:
     - ENV_VAR: use process.env as is, i.e. case sensitive on Unix, case insensitive on Windows
     - others:
        - case sensitive
        - lowercase (unless user-defined)
  - available variables (in lowest priority order):
     - CONF.system:
        - {{ENV_VAR}}
        - {{os}} {{os_full}}
        - runner-specific variable, e.g. {{node_major_version}}
     - `cli` runner:
        - {{ENV_VAR}}
        - {{before}}, {{main}}
        - {{inputId}}

Persist result.tasks|inputs|systems|commands:
  - only data which cannot be computed: id|title|description
     - mean|rank should be computed during load normalization instead
  - do not persist result.combinations[*].*Title|Description
     - add those during load normalization instead
     - only persist result.combinations[*].*Id|stats

Execute `listResults()` earlier:
  - after config retrieval
  - before:
     - `bench` command: combination list computing
     - `show|remove` command: retrieving specific result (i.e. split `getFromStore` into two)
  - reasons:
     - with CONF.merge, allows skipping already saved combinations
        - including when continuing stopped benchmark
     - show previous|diff during progress|live reporting
     - fail benchmark fast if problem with store

After listResults(), core should normalize partialResults to results:
  - perform an array of reducing functions:
     - meant for migration, when a new release of spyd is making changes to result properties
     - array is empty for the moment
  - filter by tasks|inputs|systems
  - sort by partialResult.timestamp
  - group partialResults to result using partialResult.mergeId
     - partialResult.id -> not kept in result
     - partialResult.mergeId -> result.id
  - silently filter out duplicate combinations (same mergeId+taskId+inputId+systemId)
     - reason: might happen if two results with same mergeId ran in parallel
     - keep one with earliest timestamp

store.add(result) -> store.add(partialResult)
  - i.e. append only, not merged with previous ones
  - same for addResult()

Add in comment and --help that CONF.merge is meant only for doing a single benchmark but incrementally:
  - parallelize benchmarks across identical machines (including in CI): same mergeId, same systemId
  - benchmark across different machines|hardware|software (including in CI): same mergeId, different systemId
  - continue stopped benchmark

When merging combination and there is a duplicate of same mergeId and taskId+inputId+systemId:
  - different os|cpu|memory|git|runnerConfig|duration|parallel:
     - throw and suggest to either use a different systemId, or make a different benchmark
     - reason: merge is meant for incremental benchmarks, i.e. combinations must be comparable
  - different CI build|job:
     - merge:
        - if one has no CI build|job URL, use other
        - if same CI job URL, use it
        - if same CI build URL, use it
        - if several CI build URLs, use the new one
     - reason: benchmark parallelized on several machines
  - different timestamp: keep earliest
  - no difference check if different systemId
     - only appends to result.systems
     - reasons: using systems to compare machines, spyd|runner config, git branches

CONF.merge skipping previous combinations:
  - if CONF.merge in `bench` command, do not measure (but still report) combinations already saved
  - reason: CONF.merge is meant for incremental benchmarks, including continuing stopped benchmark

Stopping benchmark:
  - on `SIGINT`, `SIGBREAK`, `SIGHUP` or `SIGTERM`
     - either interactive TTY or not
     - including if CONF.duration 0
  - serialize current measuring state (including all `measures`) to file
     - in GLOBAL_CACHE_DIR/HASH/stopped_benchmark.json
        - HASH is SHA1 of normalized absolute file path of CONF.settings
  - only last stopped benchmark (for a given CONF.settings) is saved
  - CONF.continue BOOL:
     - if true and there is a stopped_benchmark.json, use it to continue the last stopped benchmark
     - must use similar settings
        - e.g. main config values (like duration), combinations ids
        - figure out the exact set of settings to compare.
           - some are ok to change, e.g. reporting-related
  - remove CONF.merge "" to mean "same|last result"

Allow comparing different systems in a single benchmark:
  - CONF.system "systemId"[_ARR]
     - id not title, i.e. no slugification
     - if several, creates several combinations in current benchmark
     - def: ['default'] (title "Default system")
     - used to target results in `show|remove` commands too
  - CONF.system-{systemId}-VAR:
     - title STR (def: "systemId")
     - runner-{runnerId}-VAR
     - duration|parallel
     - parsing needs to take into account that systemId might have a "-"

Deltas:
  - in `show|remove` commands, and CONF.since|diff
  - computed by core
  - based on listResults() output, after tasks|inputs|systems filtering
     - reason: if a user is doing `bench` always filtered for specific tasks|inputs|systems, without using CONF.merge (e.g.  each task is a library, and is only recomputed on a new version of the library), then `show` or default CONF.diff 1 should compare each combination to the latest which had same taskId|inputId|systemId
        - should document this, since it is an alternative to CONF.merge, with similar goals for settings slow or with many dimensions
  - can be:
     - absolute timestamp
     - relative duration like "3m"
     - NUM
     - mergeId
  - operates on results, not on partialResults
  - when using timestamps|duration, should retrieve the full result
     - even if some partialResult are before, some after the timestamp, for this specific result
  - delta which cannot be resolved should:
     - CONF.since: empty array
        - reason: allows not doing `sync` before `bench` in CI
     - CONF.diff: same as no diff
     - `show|remove`: error
  - for relative duration and NUM, base:
     - CONF.since|diff in `show|remove` command: shown result
     - otherwise, latest|now
  - for absolute|relative date: target the closest earlier (not later) result

CONF.since VAL
  - filters result.previous
     - does not impact other deltas resolution (`show|remove`, CONF.diff)
  - VAL is delta, or "" (def, no filtering)
  - same delta as `show|remove` commands
  - result.previous maximum timestamp should be currently shown result's
     - e.g. if `show|remove` command and CONF.since delta starts after `show|remove` delta, result.previous should be empty

Stores:
  - add comment that no support for multiple stores because not very useful and bring questions around data sync
  - add comment that no need to make addResults() concurrent safe. Reasons:
     - append will be concurrent safe on many situations since the number of bytes to write is fairly small
     - unlikely two benchmarks would end exactly at same time on same machine
     - not good practice to execute two benchmarks at same time on same machine
     - can easily fix it by doing a `sync`
  - store.start(storeConfig) -> FUNC(storeConfig)->store instead (closure)
  - always saved at SETTINGS/results.ndjson
  - results use ndjson format. Reasons:
     - JSON parsing much faster than YAML
     - appending a file is much faster than writing the whole file
  - results file vs store:
     - results file logic is not considered a store
        - built-in, not configurable except for file location
        - not loaded like the stores
        - uses functions: addResult(), listResults(), removeResult(), syncResults()
           - result file location is passed as argument (no start())
     - listResults() at the beginning of `bench|show|remove`
        - load full|unfiltered data
     - if CONF.save true:
        - await store.add()
        - if no error, then do addResult()
     - `remove` command:
        - await store.remove()
        - if no error, then do removeResult()
     - `sync` command:
        - store.list()->OBJ_ARR
           - load full|unfiltered data
        - then syncResults(OBJ_ARR)
           - no more store.replace() method

CONF.quiet true:
  - for all commands
  - effect:
     - no console.log()
        - no logs on `debug` command
        - exception: errors are still printed
     - CONF.progress|report forces to empty ARR
  - remove CONF.progress|report "silent"

Reporting on `remove` command:
  - call reporters, like `show`
  - then prompt for removal confirmation
     - unless CONF.force true
  - then print confirmation removal suceeded
     - unless CONF.quiet true

Named exports in task files:
  - instead of exporting `tasks` array of objects, export each object individually
     - for `cli` runner, means top-level property of YAML whole file, which is a plain object
  - export name is the default value for `task.id`, which can be overridden
  - some known properties (`inputs` and `shell`) are also exported. Users can still use those words as task `id` by specifying them as `task.id` explicitely
  - both in `node` and `cli` runners

Shortcut notation in task files:
  - instead of a plain object, if only property is `main`, can use:
     - `node` runner: function
     - `cli` runner: string

CONF.run-cli.shell:
  - instead of taskFile.shell
  - STR instead of BOOL: "none", "sh", "bash"
  - should default to "none" instead
  - `cli` runner system variables:
     - if "none": none
     - if "bash": id "shell", title "Shell", value "bash_X_Y_Z", description "Bash X.Y.Z"
     - if "sh": id "shell", title "Shell", value "sh_X_Y_Z", description "sh X.Y.Z"

Error handling:
  - better way for all plugins (report, progress, stores, runners) to signal user error vs bugs
  - better handling of child process errors due to runner bugs (handled as user error right now)
  - plugin|core errors should print message to report GitHub issues to the plugin|core
     - it should include system information

CONF.debug BOOL
  - add debug information, for bug reports
  - add to issue template
  - for all actions
  - print:
     - resolved config
     - task files
     - runner system variables
     - combinations
     - each sample's state (including maxDuration, repeat, etc.)
     - last result, new partialResult, new result
  - do not call reporters

Learn package 'simple-statistics' and use it in spyd???

When killing child process, should kill descendants too
  - e.g. with spyd-runner-cli and command 'yes', 'yes' keeps executing after timeout

Consider lowering the valid Node version for spyd-runner-node, so that `run.node.versions` can target lower versions

Add REPL to evaluate Node.js or `cli` runner task on-the-fly???

Create a store that works in GitHub actions???

Add progress reporters:
  - spinner with task name and current median
  - progress bar
  - both above (def)

Reporters:
  - types:
     - JSON
     - CLI list
     - CLI table
     - Markdown list
     - Markdown table
     - CLI graphs|histograms
     - CLI where the tasks are in both axis, and the cells are the difference in %
     - CLI with horizontal bars for medians
        - with full CLI width for slowest median
        - still show numbers on top of bars (or on their left side)
        - def reporter instead of simple CLI list, except when there is only one combination
        - for Markdown too???
     - HTML
     - CLI time series (with previous combinations)
  - CLI|Markdown list:
     - follow the formatting I used in fast-cartesian example
        - simple list for TASK with no inputs
  - CLI|Markdown tables:
     - inputs as x axis, tasks as y axis
  - default reporter:
     - CLI|Markdown table if more than half of cells would be filled, and some TASK.inputs are defined
        - CLI|Markdown list otherwise
     - Markdown table|list if CONF.insert '*.md|*.markdown|README|readme'
        - CLI table|list otherwise

Make `precise-now` work on browser + node

Split `precise-timestamp` to own repository
  - make it work on browser + node
  - problem with browser: performance.now() is made only ms-precise by browser due to security timing attacks

Separate into different repos:
  - some plugins are builtin, i.e. required as production dependencies by core
     - including spyd-run-node and spyd-run-cli (until more runners are created)
  - types: spyd-report|progress|run|store-*
  - spyd -> spyd (CLI) + spyd-core (non-CLI)

Clarify features in `README`:
  - most precise and accurate benchmarking
  - pretty reporting
  - comparison with previous results
  - performance testing
  - automatically insert latest results into your documentation
  - custom reporters
  - TypeScript support
  - CI-friendly

Add tests, documentation, etc.:
  - for all repos, including sub-repos
  - add keywords (GitHub, package.json)

Use key-value abstraction layers to add more built-in spyd-store-*

Utilities to help people creating reporters, runners, progress reporters, stores
  - GitHub template
  - test utility

Competitors benchmark:
  - benchmark with other benchmarking tools
  - each should measure Math.random() for the same duration
     - use different durations as inputs
  - report both medians (for accuracy) and standard deviation (for precision)

Add roadmap:
  - point to it from contribution doc to orient contributors towards features I want (e.g. HTML reporter)

Promote

Add other runners:
  - spyd-run-chrome (maybe using puppetter)
  - spyd-run-firefox (maybe using puppetter-firefox)
  - spyd-run-selenium
  - spyd-run-bash
  - spyd-run-go

Commercial offer:
  - reporting dashboard:
     - show time series (i.e. keep history)
        - should not lose history when change only the `title` of the function|variant
     - nice data visualization
     - should show function bodies
  - code editor for tasks files:
     - perform benchmark (inside browser not on our servers)
     - send results to API (like what users would do on CI otherwise)
     - show results from API
     - i.e. can be used like jsperf
  - Sharing like jsperf:
     - allow users to benchmark in their own browsers
  - PR bot
  - notifications
  - user should report results to our API
     - like Codecov does
     - i.e. we do not pay for infrastructure cost, except simple CRUD API to store results
     - should be integrated with CI (i.e. use `ci-info`)
  - pricing:
     - free for open source
     - pay per private repo
