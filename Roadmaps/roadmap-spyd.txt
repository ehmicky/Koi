
        
   SPYD  
        



Upgrade all my .travis.yml to use `dist: bionic`

nve (release/v3 branch):
  - allow `NVM_NODEJS_ORG_MIRROR` and `N_NODE_MIRROR` and `NODIST_NODE_MIRROR` as alternative to `NODE_MIRROR` (do not document)
  - add CLI to all-node-versions
  - allow both n [VERSION] node ... and n [VERSION] ... (same thing)
     - try to recognize if first arg looks like a binary
        - e.g. does not start with -, has only \w+ and is not a path to an existing file
  - go through whole nve code again
  - check if `xz --version` exit code is 0, and if so, download *.tar.xz instead of *.tar.gz
     - except for AIX or if Node <0.12.10
  - "Downloading Node.js" -> "Downloading Node.js X.Y.Z"
  - automatically cleanup caches of Node.js versions that haven't been used lately, or maintain a maximum number of cache per machine
  - update benchmarks
  - fix documentation and examples
     - include the fact that since this is now a full-fledge alternative to nvm, no need to point to it anymore
  - submit nve to https://github.com/sindresorhus/awesome-nodejs
  - spyd --run.node.versions should use nve somehow (instead of get-node), so that child processes use the right Node.js version

Learn package 'simple-statistics' and use it in spyd

Separate into different repos:
  (builtin plugins are required as production dependencies by core)
  - spyd-report-*
  - spyd-run-*
  - spyd-store-*
  - spyd-progress-*

Add progress reporters:
  - spinner with task name and current median
  - progress bar
  - both above (def)

Reporters:
  - types:
     - JSON
     - CLI list
     - CLI table
     - Markdown list
     - Markdown table
     - CLI graphs|histograms
     - CLI where the tasks are in both axis, and the cells are the difference in %
     - CLI with horizontal bars for medians
        - with full CLI width for slowest median
        - still show numbers on top of bars (or on their left side)
        - def reporter instead of simple CLI list, except when there is only one iteration
        - for Markdown too???
     - HTML
     - CLI time series (with previous iterations)
  - CLI|Markdown list:
     - follow the formatting I used in fast-cartesian example
        - simple list for TASK with no variations
  - CLI|Markdown tables:
     - variations as x axis, tasks as y axis
  - default reporter:
     - CLI|Markdown table if more than half of cells would be filled, and some TASK.variations are defined
        - CLI|Markdown list otherwise
     - Markdown table|list if OPTS.insert '*.md|*.markdown|README|readme'
        - CLI table|list otherwise
  - when BENCHMARK.histogram|percentiles [], reporters should show "Not enough data" (but not throw)
  - Markdown|HTML reporters should add "Benchmarked with [spyd](https://github.com/ehmicky/spyd)" when REPORTER_OPTS.link true
     - but CLI reporters should never add anything (except 'debug' reporter)

When killing child process, should kill descendants too
  - e.g. with spyd-runner-cli and command 'yes', 'yes' keeps running after timeout

Competitors benchmark:
  - benchmark with other benchmarking tools
  - each should benchmark Math.random() for the same duration
     - use different durations as variations
  - report both medians (for accuracy) and standard deviation (for precision)

Add tests, documentation, etc.:
  - for all repos, including sub-repos

Consider lowering the valid Node version for spyd-runner-node, so that `run.node.versions` can target lower versions

Validation|testing utility to help people creating reporters, runners, progress reporters

Add other runners:
  - spyd-run-chrome (maybe using puppetter)
  - spyd-run-firefox (maybe using puppetter-firefox)
  - spyd-run-selenium
  - spyd-run-bash

Add roadmap:
  - point to it from contribution doc to orient contributors towards features I want (e.g. HTML reporter)

Promote:
  - add keywords (GitHub, package.json)

Features:
  - most precise and accurate benchmarking
  - pretty reporting
  - comparison with previous benchmarks
  - performance testing
  - automatically insert latest benchmarks into your documentation
  - custom reporters
  - TypeScript support
  - CI-friendly

Commercial offer:
  - reporting dashboard:
     - show time series (i.e. keep history)
        - should not lose history when change only the `title` of the function|variant
     - nice data visualization
     - should show function bodies
  - code editor for benchmark files:
     - run benchmarks (inside browser not on our servers)
     - send benchmark results to API (like what users would do on CI otherwise)
     - show results from API
     - i.e. can be used like jsperf
  - Sharing like jsperf:
     - allow users to run in their own browsers
  - PR bot
  - notifications
  - user should report benchmark results to our API
     - like Codecov does
     - i.e. we do not pay for infrastructure cost, except simple CRUD API to store benchmark results
     - should be integrated with CI (i.e. use `ci-info`)
  - pricing:
     - free for open source
     - pay per private repo
