
        
   SPYD  
        



Fix `exec`
  - e.g. `stdio` must be [`ignore`, `inherit`, `inherit`]
  - pSetTimeout() should be either unref() or clearTimeout(), otherwise it will hold the process
     - take into account that duration might be 0 or 1
  - should show ids, not titles

Fix CLI runner

Fix `src/combinations/main.js` that is currently hardcoded
  - instead of exporting tasks OBJ_ARR, named exports: beforeAll|beforeEach|main|afterEach|afterAll
  - add comment why each task file contains a single task: faster to spawn

Go through whole code, looking for bugs

Precision:
  - compare precision:
     - compare with multiple processes:
        - variance between combinations of single benchmark, vs between single combinations of different benchmarks
        - median vs standard deviation vs variation between processes
        - small CONF.duration vs big CONF.duration
  - note: using a "for loop" without spyd does work:
     - increasing the count makes the results more and more precise
     - the first 2 loops (regardless of the total count) always seem to be different from others
  - check if using a fixed, low amount of processes helps with precision???
  - find ways to improve precision even more???

Live updating:
  - steps:
     - reporter.report()->STR:
        - done after each measures aggregation:
           - counted as part of the `aggregateDuration`
           - unless repeatInit false
              - reason: if repeatInit false, measures will be removed, which would create confusing reporting (e.g. for min|max)
              - other reason: during repeatInit false, stats change a lot, creating flicker
     - do I/O using the last reporter.report() STR
        - done during progress reporting interval function
           - not counted as part of the `aggregateDuration`
  - both steps are:
     - also initially done right after combinations are available, showing no stats yet
     - only done if all of:
        - reporter.progress true (def: false)
        - reportConfig.output "-"
        - CONF.quiet false
  - call reporter.report()->STR with same arguments as the final reporter.report():
     - including result being normalized
     - including having information from initial listResults() (e.g. for previous combinations and diff)
     - including all possible result.combinations, even ones not measured yet
     - excluding CONF.show, always empty
  - if reporter.progress false, reporter.report() can be async. If true, cannot.
  - progress reporter is appended to it:
     - performed right after each live reporting
  - limit the amount of changes of the general shape of the output between the initial call and the final one, to make it look nicer
     - e.g. tables should be initially shown with all rows|columns and empty cells
  - when:
     - ending benchmark: clean progress reporting. Report again (do not keep the last live reporting)
     - stopping benchmark once: clean progress reporting. Report again (do not keep the last live reporting)
     - stopping benchmark twice: clean progress reporting. Keep last live reporting
  - default CONF.duration should be 0 when some reporters are live updating instead

CONF.concurrency NUM
  - validate that CONF.concurrency NUM is integer >=1
  - each sample spawns NUM processes in parallel
     - in `bench` command, but not in `exec` command
     - start|end group of processes together
     - use same `params`, including `maxLoops`
     - if one process fails
        - the other ones should continue (for cleanup)
        - but the sample should then propagate error
     - measureCost computation should use the same amount of parallel processes
  - add code comment that:
     - CONF.concurrency is meant to measure cost of parallelism
        - both CPU and I/O parallelism
     - if task is I/O bound, it can also improve precision by performing more measures, at the cost of accuracy (due to cost of parallelism)
        - the number where parallel processes start competing for CPU depends on how much duration the task spend on CPU vs I/O
        - above that number:
           - median measure increases much more
           - precision decreases much more
     - move the current code comment from src/measure/combination.js (about spawning processes serially)
  - handle spawn errors due to too many processes at once
     - try to remove process limit with ulimit, and see if another error can happen with a high CONF.concurrency, e.g. too many open files

isAsync:
  - initial check for isAsync:
     - execute func once, without await
     - check if return value is promisable (using p-is-promise)
     - sets func.isAsync BOOL (originally undefined)
     - if isAsync, await return value
  - do the above when func.isAsync undefined && repeat 1
     - add code comment that repeat should always be 1 when func.isAsync undefined, and this probably won't change. It is more of a failsafe.
  - do the above in a `sync_async` dir, next to `sync` and `async` dirs
  - do the above independently for beforeEach, main and afterEach
  - always use await on beforeAll|afterAll, i.e. allow both sync and async
  - remove task.async BOOL

Quantiles|histogram:
  - persist in stores
  - some stats should have a space-efficient shape for stores, but be denormalized on load:
     - histogram:
        - denormalized: OBJ_ARR: low, high, frequency
        - normalized: ARR of [high, frequency]
     - quantiles:
        - denormalized: OBJ_ARR: percentage NUM, value NUM
        - normalized: NUM_ARR
     - both: use difference from median in durations
  - show in `debug` reporter

reporter.debugStats BOOL
  - def: false
  - true for `debug` reporter
  - if false, do not pass:
     - mean
        - add comment that we must ensure median is the main one used, so different reporters are consistent, and also because it is used in sorting combinations, and also it is less precise
     - times
        - add comment that it is a bad indicator of precision, and also might be confused as an indicator of speed due to other benchmark libraries showing it like that
     - minLoopDuration, samples, repeat, loops

Sort all the code comments in `measure`, `sample`, `stats`, `process` and the `node|cli` runners. It's a bit messy right now, and some might be outdated

result.systems:
  - still an OBJ_ARR, one per systemId
  - result.systems[0] -> result.sharedSystem
     - created on results load
  - result.systems[*]:
     - id STR
     - title STR
        - def: same as id
     - machine: os|memory|cpu
     - versions OBJ
        - all runner.versions shallow merged
        - not versions.RUNNER.VAR: all runners shallow merge their versions OBJ, using CONF.tasks.* order as priority order
     - git
        - not result.git
     - ci "URL"
        - not OBJ, and not result.ci
     - no more config nor runConfig
        - should use propSets instead
  - reporting|measuring systems:
     - CONF.system is only for `bench` command, i.e. only one system
     - CONF.include|exclude is only for reporting in `show|remove` commands, i.e. allow reporting several systems
  - add comment that system is only for out-of-spyd env: hardware, OS, git branch, env vars, etc.

runner.config.PROP.example STR[_ARR]
  - for all plugins: reporter, progress, runner, store
  - meant for validation, using jest-validate (same validation as for CONF.*):
     - validate against unknown props
     - if ARR, use multipleValidOptions()
  - required

Do not allow CONF.tasks|input|runner|system with the `show|remove` commands

Allow spyd.js|mjs|cjs|ts
  - loaded with require()
  - allow CONF.extend to be a "MODULE"
     - i.e. use require() unless start with . or /

Cwd:
  - use spyd.yml's directory as the cwd for everything
     - exception: CONF.* file paths specified as CLI flags or environment variables (not inside spyd.yml)
        - i.e. config|extend|output|insert
        - also any plugin config with plugin.config.PROP.path true
           - i.e. plugin.config.PROP -> plugin.config.PROP.example
        - resolved during config load
  - remove CONF.cwd
  - remove cwd from store.start()

Tasks and runners selection
  - CONF.tasks.RUNNER 'GLOB'[_ARR]
     - def: empty ARR, i.e. tasks must be explicitly set
     - RUNNER that are used and loaded are the ones with at least one matching file
        - single task file can target several runners, which spawns several combinations
  - task ID is up until first dot in filename
     - this allows two different task files with same ID
     - validate that no two task files have same taskId + runner
        - but can have same taskId and different runner, or vice-versa
  - remove runner.extensions
  - add code comment that we use explicit CONF.tasks.RUNNER instead of:
     - using code comment
        - bad performance with big files
        - transpiling removing comments
        - does not work in compiled binaries
     - using filenames:
        - does not work will with multiple runners per task
        - leads to odd filenames when runner and extension are similar|same
     - guessing using require()
        - too implicit/magic
        - would also find dependencies dependencies
        - does not work well with bundled runners

ID validation:
  - for user-defined (task|input|system):
     - [[a-zA-Z0-9]_-]+
     - no empty string
  - for plugins (report|run|store|progress) and configuration properties (including runConfig):
     - [a-z][a-z0-9]*
     - no empty string
     - no _
        - reason: not allowed in npm package name
        - reason: used as config property delimiter
     - no .
        - reason: not allowed in npm package name
     - no -
        - reason: confusing when mixed with _ delimiter in config properties
        - reason: not friendly in envvars

Add comment that we enforce [a-z][a-z0-9_]* in configuration property names
  - in core (as opposed to plugins), we try to avoid _ too
  - reasons:
     - no mixed case, because it is not common in CLI flags nor environment variables
     - consistent option name across spyd.yml, CLI flags, envvars, programmatic
     - no multiple delimiters

Validate that there are no duplicate ids for tasks|inputs|systems|propSets|runners
  - reason: allows using id only (without specifyig the type) in some contexts, e.g. CONF.include|exclude

Remove commands dimension:
  - runner.launch() returns a single OBJ instead of OBJ_ARR:
     - commands is not a input-like dimension anymore, including in:
        - combination.name|columnName
        - combination.commandRank
        - combination.previous
        - combinations sorting
        - duplication removal
        - commandId in CONF.limit
        - `show`/`remove` command filtering
        - result.commands[Pretty]
     - returned OBJ properties:
        - spawn ['FILE', 'ARG',...]
        - spawnOptions OBJ (def: {})
        - versions OBJ:
           - instead of runner.system
           - OBJ values can be either STR (direct value) or STR_ARR (command to retrieve stdout from, all called in parallel)
           - meant for software versions, mode (e.g. type of shell) and options
        - not needed anymore:
           - id -> not needed anymore since no more targetting
           - title|description -> runner.id|title
     - can optionally be directly a OBJ instead of FUNC()->[PROMISE_]OBJ
  - remove any instances of the word "command", except for CLI commands, to avoid confusion
     - commandConfig -> runConfig

Better titles:
  - specified in CONF.titles
     - OBJ:
        - key is id
        - value is title STR
     - can be any dimension: task, input, system, propSets, runner
     - reasons:
        - no need to wait for processes spawn to start displaying task titles
        - single place for users to specify titles for tasks, inputs and systems, i.e. simpler
        - simpler for runner, which do not need to handle titles
  - default title:
     - task, input, system, propSets: same as id
        - default system is not shown in core reporters (since sharedSystem is top-level)
     - runner: runner.title
  - CONF.show "titles"
     - if absent, show ids, not titles
        - reason: making id clear to users for CONF.include|exclude
     - def: absent
  - remove title specified in:
     - task.title
     - inputs
     - no more need to return inputTitle|taskTitle from runner.start()

CONF.input.INPUT VAL
  - instead of inputs inside tasks
  - not only for dimensions: can be used to simply pass inputs to tasks, e.g. loop sizes
  - VAL can be any JSON type
     - if OBJ, must use propSets to avoid ambiguity
  - runner.measure() gets `input` { INPUT: VAL, ... } instead of inputId
     - when using propSets, key is 'INPUT' not 'INPUT.ID'
  - multiple inputs dimensions:
     - use propSets
        - i.e. CONF.input.INPUT.ID VAL
        - same behavior for cartesian product, CONF.include|exclude, etc.
     - `input` passed to runner.measure() is same, i.e. key is 'INPUT' not 'INPUT.ID'
     - propItemId is 'INPUT.ID' not 'input.INPUT.ID'

propSets:
  - name:
     - propSet: whole dimension
     - propItem: each item in a propSet
     - called "configuration property sets" in comments and documentation
  - some config properties can optional be PROP: { ID: VAL, ... } instead of VAL
     - if same PROP -> same propSet
     - if same PROP + ID -> same propItem
  - when merging results:
     - if some PROP uses propSets in one result, but not in another
     - then use ID 'default' to convert so all instances of that PROP have a propSet
     - this allows keeping history continuity when introducing propItems
  - only on any CONF.* that can change the results:
     - CONF.concurrency
     - CONF.duration
     - CONF.input.INPUT
     - any CONF.run.{runnerId}.PROP
        - cartesian product only to combinations with that runner
  - each propSet is a separate dimension, distinct from other propSets:
     - in CONF.include|exclude
     - in combination.columnName: several STR
     - result.propSets OBJ_ARR_ARR, not OBJ_ARR
     - combination.propSets ARR
  - propItemId:
     - 'PROP.ID' (not just 'ID')
        - exclude 'input.' and 'runner.' in 'PROP.', to be short
     - used as identifier like for other dimensions, including:
        - comparing between combinations (including between different benchmarks)
        - selecting with CONF.include|exclude|limit
  - propItemValue: property VAL
  - propItemTitle: default to same as id
  - set on result.* like other dimensions:
     - for combinations sorting, mean, rank, selection, etc.
     - result.propSets OBJ_ARR_ARR: id STR, value VAL, title STR
     - combination.propSets OBJ_ARR: id STR, value VAL, title STR
  - just like tasks and inputs, only reported in main reporting table, not in system info below it
  - if several propItems have different runner.versions.VAR VAL, they are concatenated as a result.systems[*].versions.VAR ARR
     - printed as a comma-separated list by reporter prettify logic
     - does not mention which propItem used which ones. It should be obvious enough from ids or titles

CONF.include|exclude STR_ARR
  - possible combinations are cartesian product of: tasks, inputs, runners, propSets, systems
  - format:
     - CONF.include|exclude STR_ARR
        - def:
           - include: all
           - exclude: none
        - combination is used if included and not excluded
     - STR_ARR: does union
        - each STR do not need to share same dimensions
     - STR is a space-separated list of groups
        - groups are intersected
        - groups must all be from different dimensions
     - each group is a comma-separated list of IDs
        - all IDs must be from same dimension
        - can prepend ! to whole group to invert its selection
           - done before intersecting with other groups
        - no space allowed around comma
  - add comment why CONF.include + CONF.exclude instead of single CONF.include:
     - otherwise, exclusions would be quite verbose in CONF.include, since they would need to be added to each STR
     - also, this allows overriding CONF.include in the CLI while keeping the exclusions, which is most likely wanted
  - no more need for:
     - CONF.tasks|inputs
     - task.inputs
  - CONF.limit should be STR_ARR with same format as CONF.include
     - except each STR is prepended with percentage (then space) and IDs are optional

CONF.info|context -> CONF.show STR_ARR among 'system', 'metadata'
  - if no:
     - 'system': pass `undefined` to reporters for result.sharedSystem|systems[*].machine|versions|spyd
     - 'metadata': pass `undefined` to reporters for result.sharedSystem|systems[*].git|ci and result.id|timestamp
  - default value:
     - has "system" if CONF.system defined
     - has "metadata" if `show|remove` command

Spyd link in reporter
  - should be presented as spyd version instead:
     - "Benchmarked by [spyd vX.Y.Z](URL to GitHub release)
  - persist result.spydVersion "X.Y.Z"
     - on load, normalized to results.spyd OBJ:
        - version "X.Y.Z"
        - release "URL" to GitHub release
  - remove CONF.link BOOL
     - instead, make it part of CONF.show "system"
        - when not present, result.spyd should be undefined
        - should also be undefined when printing to interactive terminal

Variables in `cli` runner:
  - remove user-defined `variables`. Can use either subshells, or command wrapper instead
  - use stdout "pipeInherit":
     - in beforeAll, beforeEach and main
     - only if variable is used by another command
  - validate against using a variable in the wrong command
     - beforeAll: only beforeEach|main|afterEach|afterAll
     - beforeEach: only main|afterEach
     - main: only afterEach
     - afterEach, afterAll: none
     - any other: none
  - available variables (in lowest priority order):
     - {{ENV_VAR}}
        - use process.env as is, i.e. case sensitive on Unix, case insensitive on Windows
     - {{beforeAll}}, {{beforeEach}}, {{main}}
     - {{inputId}}

combination.name|columnName:
  - task dimension not present if all combinations have same value (like other dimensions)
     - exception: if single dimension, show only task
  - columnName order is input, system, runner, propSets
  - if there are runner-specific propSets
     - must be last
     - empty values (when on different runners) removed
        - i.e. different propSets for different runners might be aligned together
     - columnName arrays should all have same length, by appending empty strings
        - i.e. if one runner has 1 propSet, and another has 2, the first gets an empty string appended
  - fix combination error task prefix, so it shows all the dimensions
     - except the ones not useful, e.g. system (since there is only one per execution), or inputs if none are used, etc.

Persist result.tasks|inputs|systems|commands:
  - only data which cannot be computed: id|title
     - mean|rank should be computed during load normalization instead
  - do not persist result.combinations[*].*Title
     - add those during load normalization instead
     - only persist result.combinations[*].*Id|stats

Execute `listResults()` earlier:
  - after config retrieval
  - before:
     - `bench` command: combination list computing
     - `show|remove` command: retrieving specific result (i.e. split `getFromStore` into two)
  - reasons:
     - show previous|diff during progress|live reporting
     - fail benchmark fast if problem with store

After listResults(), perform an array of reducing functions:
  - meant for migration, when a new release of spyd is making changes to result properties
  - array is empty for the moment

Sorting:
  - done after listResults()
  - used by:
     - result.previous
     - merging
  - order:
     - mostly based on partialResult.timestamp
     - if some previous partialResults have same CI build URL (not job), and one has that combination, use only those partialResults
     - otherwise, do same check but using git commit

New merging logic:
  - bench action:
     - measure|report combinations:
        - from the current partialResult
        - filtered by the current CONF.include|exclude
     - reasons:
        - stronger focus during bench action on the combination being measured
        - remove need during the bench action to have separate CONF.include|exclude for measuring and reporting, which is simpler
           - instead, users should two separate bench then show actions if they want to measure only few combinations then report all of them
  - show|remove actions:
     - report combinations:
        - from the target partialResult
           - any later partialResults are ignored
        - filtered by the current CONF.include|exclude
           - not the CONF.include|exclude from when the partialResult was taken
        - if CONF.include selects combinations present in previous partialResults but absent in target partialResult, merge them:
           - the "latest" combination is used
              - must be before the partialResult was taken
              - "latest" is according to "sorting order" (see above)
              - if none found, silently ignore it
     - reasons:
        - when merging partialResult, cannot know the intended set of combinations since:
           - user might have changed it when the partialResult was measured by passing CONF.tasks|input or (if propSets) CONF.duration|concurrency|runner.RUNNER.PROP
           - partialResult always has a single CONF.system, and it is hard to know whether previous results' systems have been now removed or not
        - so the user must specify explicitely which additional dimensions are intended to be reported
        - only merging explicitly gives predictable results users would expect
        - makes more sense for time series reporters
     - when several combinations have different:
        - timestamp: keep earliest
        - spydVersion: keep the lowest one
        - CI build|job:
           - merge:
              - if one has no CI build|job URL, use other
              - if same CI job URL, use it
              - if same CI build URL, use it
              - if several CI build URLs, use the new one
           - reason: benchmark parallelized on several machines
  - remove CONF.merge

store.add(result) -> store.add(partialResult)
  - i.e. append only, not merged with previous ones
  - same for addResult()

Deltas:
  - in `show|remove` commands, and CONF.since|diff
  - computed by core
  - can be:
     - absolute timestamp
     - relative duration like "3m"
     - NUM
  - operates on partialResults, not results
     - after CONF.include|exclude filtering
  - delta which cannot be resolved should:
     - CONF.since: empty array
        - reason: allows not doing `sync` before `bench` in CI
     - CONF.diff: same as no diff
     - `show|remove`: error
  - for relative duration and NUM, base:
     - CONF.since|diff in `show|remove` command: shown result
     - otherwise, latest|now
  - for absolute|relative date: target the closest earlier (not later) result

CONF.since VAL
  - filters result.previous
     - does not impact other deltas resolution (`show|remove`, CONF.diff)
  - VAL is delta, or "" (def, no filtering)
  - same delta as `show|remove` commands
  - result.previous maximum timestamp should be currently shown result's
     - e.g. if `show|remove` command and CONF.since delta starts after `show|remove` delta, result.previous should be empty

Stores:
  - add comment that no support for multiple stores because not very useful and bring questions around data sync
  - add comment that no need to make addResults() concurrent safe. Reasons:
     - append will be concurrent safe on many situations since the number of bytes to write is fairly small
     - unlikely two benchmarks would end exactly at same time on same machine
     - not good practice to execute two benchmarks at same time on same machine
     - can easily fix it by doing a `sync`
  - store.start(storeConfig) -> FUNC(storeConfig)->store instead (closure)
  - always saved at SETTINGS/history.ndjson
  - results use ndjson format. Reasons:
     - JSON parsing much faster than YAML
     - appending a file is much faster than writing the whole file
  - results file vs store:
     - results file logic is not considered a store
        - built-in, not configurable except for file location
        - not loaded like the stores
        - uses functions: addResult(), listResults(), removeResult(), syncResults()
           - result file location is passed as argument (no start())
     - listResults() at the beginning of `bench|show|remove`
        - load full|unfiltered data
     - if CONF.save true:
        - await store.add()
        - if no error, then do addResult()
     - `remove` command:
        - await store.remove()
        - if no error, then do removeResult()
     - `sync` command:
        - store.list()->OBJ_ARR
           - load full|unfiltered data
        - then syncResults(OBJ_ARR)
           - no more store.replace() method

Reporting on `remove` command:
  - call reporters, like `show`
     - i.e. must accept same CONF.*, e.g. CONF.tasks|system
  - then prompt for removal confirmation
     - unless CONF.force true
  - do not print that confirmation removal suceeded (but print error if failed)

CONF.run-cli.shell:
  - instead of taskFile.shell
  - STR instead of BOOL: "none", "sh", "bash"
  - should default to "none" instead
  - `cli` runner.versions:
     - if "none": none
     - if "bash|sh": { Bash|sh: 'X.Y.Z'}

Plugin shape should be validated:
  - including that plugin properties values cannot be OBJ
     - reason: nesting does not work well in CLI flags or envvars
  - including that plugin properties names must be [a-z][a-z0-9_]*

Error handling:
  - better way for all plugins (report, progress, stores, runners) to signal user error vs bugs
  - better handling of child process errors due to runner bugs (handled as user error right now)
  - plugin|core errors should print message to report GitHub issues to the plugin|core
     - it should include system information

CONF.debug BOOL
  - add debug information, for bug reports
  - add to issue template
  - for all actions
  - print:
     - resolved config
     - task files
     - runner.versions
     - combinations
     - each sample's state (including maxDuration, repeat, etc.)
     - last result, new partialResult, new result
  - do not call reporters

Learn package 'simple-statistics' and use it in spyd???

When killing child process, should kill descendants too
  - e.g. with spyd-runner-cli and command 'yes', 'yes' keeps executing after timeout

Consider lowering the valid Node version for spyd-runner-node, so that `run.node.versions` can target lower versions

Add REPL to evaluate Node.js or `cli` runner task on-the-fly???
  - should allow OPTS.save, so differences are shown

Create a store that works in GitHub actions???

Add progress reporters:
  - spinner with task name and current median
  - progress bar
  - both above (def)

Reporters:
  - types:
     - JSON
     - CLI list
     - CLI table
     - Markdown list
     - Markdown table
     - CLI graphs|histograms
     - CLI where the tasks are in both axis, and the cells are the difference in %
     - CLI with horizontal bars for medians
        - with full CLI width for slowest median
        - still show numbers on top of bars (or on their left side)
        - def reporter instead of simple CLI list, except when there is only one combination
        - for Markdown too???
     - HTML
     - CLI time series (with previous combinations)
  - CLI|Markdown list:
     - follow the formatting I used in fast-cartesian example
        - simple list for TASK with no inputs
  - CLI|Markdown tables:
     - inputs as x axis, tasks as y axis
  - default reporter:
     - CLI|Markdown table if more than half of cells would be filled, and some inputs are defined
        - CLI|Markdown list otherwise
     - Markdown table|list if CONF.insert '*.md|*.markdown|README|readme'
        - CLI table|list otherwise

Make `precise-now` work on browser + node

Split `precise-timestamp` to own repository
  - make it work on browser + node
  - problem with browser: performance.now() is made only ms-precise by browser due to security timing attacks

Separate into different repos:
  - some plugins are builtin, i.e. required as production dependencies by core
     - including spyd-run-node and spyd-run-cli (until more runners are created)
  - types: spyd-reporter|progress|runner|store-*
  - spyd -> spyd (CLI) + spyd-core (non-CLI)

Clarify features in `README`:
  - most precise and accurate benchmarking
  - pretty reporting
  - history
  - performance testing
  - automatically insert latest results into your documentation
  - custom reporters
  - TypeScript support
  - CI-friendly

Add tests, documentation, etc.:
  - for all repos, including sub-repos
  - add keywords (GitHub, package.json)

Use key-value abstraction layers to add more built-in spyd-store-*

Utilities to help people creating reporters, runners, progress reporters, stores
  - GitHub template
  - test utility

Competitors benchmark:
  - benchmark with other benchmarking tools
  - each should measure Math.random() for the same duration
     - use different durations as inputs
  - report both medians (for accuracy) and standard deviation (for precision)

Add roadmap:
  - point to it from contribution doc to orient contributors towards features I want (e.g. HTML reporter)

Send PRs to do or redo benchmarks of repositories to
  - get user feedback
  - experience the library as a user
  - get visibility

Promote

Add other runners:
  - spyd-runner-chrome (maybe using puppetter)
  - spyd-runner-firefox (maybe using puppetter-firefox)
  - spyd-runner-selenium
  - spyd-runner-bash
  - spyd-runner-go

Commercial offer:
  - reporting dashboard:
     - show time series (i.e. keep history)
        - should not lose history when change only the `title` of the function|variant
     - nice data visualization
     - should show function bodies
  - code editor for tasks files:
     - perform benchmark (inside browser not on our servers)
     - send results to API (like what users would do on CI otherwise)
     - show results from API
     - i.e. can be used like jsperf
  - Sharing like jsperf:
     - allow users to benchmark in their own browsers
  - PR bot
  - notifications
  - user should report results to our API
     - like Codecov does
     - i.e. we do not pay for infrastructure cost, except simple CRUD API to store results
     - should be integrated with CI (i.e. use `ci-info`)
  - pricing:
     - free for open source
     - pay per private repo
