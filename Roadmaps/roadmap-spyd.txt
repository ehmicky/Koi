
        
   SPYD  
        



New measureCost:
  - verify happy with current branch feat/measure_cost_again
  - `measures` -> `mainMeasures` (in child)
  - remove `dry`
  - try to make measureCost and processMedians use the same code
  - resolution:
     - computed together with measureCost
     - can use both mainMeasures and emptyMeasures
     - after reaching 1000, should probably stop since it is not useful anymore
  - add comment why emptyMeasures filled before each measure:
     - not in a separate process: spawning process takes too much time
     - not done after main loop instead:
        - measureCost gets faster and faster. Doing it alongside makes it closer to actual speed used in measures
        - does not re-use same `maxDuration`
        - provides with cold start for first measure
     - done on each process, using proportional duration, i.e. precision improves with higher CONF.duration
  - initial loadCost still done in a single initial process
     - with emptyDuration and mainDuration undefined
     - start should still be computed, and after task has loaded
     - do it in parallel, right after runner.load() process (in a separate process)

Check if `process_group.js` is now fast, or if there is anything that can still be made faster

Quantiles|histogram:
  - persist in stores
  - some stats should have a space-efficient shape for stores, but be denormalized on load:
     - histogram:
        - denormalized: OBJ_ARR: low, high, frequency
        - normalized: ARR of [high, frequency]
     - quantiles:
        - denormalized: OBJ_ARR: percentage NUM, value NUM
        - normalized: NUM_ARR
     - both: use difference from median in durations
  - show in `debug` reporter

reporter.debugStats BOOL
  - def: false
  - true for `debug` reporter
  - if false, do not pass:
     - mean
        - add comment that we must ensure median is the main one used, so different reporters are consistent, and also because it is used in sorting combinations, and also it is less precise
     - times
        - add comment that it is a bad indicator of precision, and also might be confused as an indicator of speed due to other benchmark libraries showing it like that
     - loadCost, measureCost, processes, repeat, loops

New processGroups logic
  - rename processes|processGroups to samples|samplingGroup
  - split samplingGroup main function into:
     - an inner function, receiving state, spawning process, computing new state and returning it
     - an outer function, passing state around and deciding which samplingGroup's inner function to call next, and computing how much time left

reportCost|measureCost progressive computation:
  - measure all samplesGroups concurrently: main one, measureCost
     - concurrent, but still one at a time
     - the samplingGroup with lowest samplingGroupDuration spent always executes next
        - exception: if last had repeatInit true, execute it again
           - unless out of samplingGroupDuration
           - i.e. do not switch to other progressGroup
     - if same samplingGroupDuration spent (including 0), priority is: measureCost > main
     - reason: not to block live reporting at the beginning of the benchmark and between each combination
  - measureCost gets 10% of combinationDuration, main gets 90%
     - i.e. after 20% of combinationDuration, only main is left executing
  - add comment that first 11% of main samplingGroup will have more imprecise measureCost when normalizing measures and computing repeat|maxDuration, but that's fine
  - the `timeResolution` should be recomputed after each measureCost sample, but `Math.min(newTimeResolution, oldTimeResolution)` should be used
  - check if `loadCost` is still different between samplingGroups
     - if not, share loadCost array|estimation between them

Measure combinations concurrently
  - concurrently, but still one at a time, using same sample orchestration logic as the one used to orchestrate measureCost|main samples
  - reason: better live reporting
  - other reason: provides with fast fail if one combination times out or throw exception
  - if two combinations have same combinationDuration left, pick a random one
     - reason: random tasks progressing is more visually interesting than sequential
  - when completing initial measureCost sample, do the first main sample right after it in order to provide with fast first reporting of each combination
  - progress reporter should not show current combination nor counter anymore
  - progress reporter durationLeft and percentage need to take into account that multiple combinations are measured concurrently

Improve precision:
  - find ways to improve precision even more???
  - tweak outliers removal:
     - find the best threshold value
     - remove outliers on both slow and fast ends???

Reporter live updating:
  - do during each live reporting, instead of end of whole combination:
     - addMeasures() (sorting and concatenating)
     - computeStats() (including mean and standard deviation)
  - sync vs async:
     - first step: the output string is computed synchronously, during sample orchestration
     - second step: the last output string is output and I/O is done, during progress reporting interval function
  - allocate 10% of total time to the output string computation:
     - all of: addMeasures(), computeStats(), reporter.report()
     - initially done right after combination titles are available
        - showing no stats yet
     - then, done again after all other combined sampleGroups have spent 9 times reportDuration
        - reportDuration is the median of the last 3 durations of live reporting
           - reason: allow adapting to increase over time, while still ignoring big reportDuration if reporting happened to be much slower from time to time
        - if sample has repeatInit true, do not live report it yet
     - if no new childMeasures, noop and do not change reportDuration
     - done by sample orchestrator
  - call reporter.report()->STR with same arguments as the final reporter.report():
     - including result being normalized
     - including having information from initial listResults() (e.g. for previous combinations and diff)
     - including all possible result.combinations, even ones not measured yet
     - excluding CONF.show, always empty
  - if reporter.progress false, reporter.report() can be async. If true, cannot.
  - progress reporter is appended to it:
     - performed right after each live reporting
  - computeStats() and reporter.report() only done:
     - if all of:
        - reporter.progress true (def: false)
        - reportConfig.output "-"
        - CONF.quiet false
     - addMeasures() is still done for incremental sorting and concatenating (to prevent big slowdown at end)
     - computeStats() and reporter.report() are also still done at end of combination
  - screen refreshing:
     - refresh whole screen at the beginning
        - use `signal-exit`
        - experiment if there is a way to refresh partial screen instead of whole screen
           - it should still work if user types newline or characters
     - each update should refresh the whole screen with the new content
        - but by printing over it, not clearing it first, to avoid flickering
        - i.e. need to padRight() the new content if the old content was larger
  - new progress.*() shape:
     - since core now handles refreshing the screen
     - progress.update():
        - must return a STR
        - must be sync
     - remove progress.start|stop()
  - limit the amount of changes of the general shape of the output between the initial call and the final one, to make it look nicer
     - e.g. tables should be initially shown with all rows|columns and empty cells

Infinite duration:
  - CONF.duration 0
  - default value for CONF.duration if interactive TTY
     - default value still 10 if not iteractive TTY
  - measures forever
  - stopping:
     - on `SIGINT`, `SIGBREAK`, `SIGHUP` or `SIGTERM`
        - either interactive TTY or not
     - keep both progress reporter and live reporter printed
     - report all other reporters too
  - progress reporter:
     - pass percentage undefined
     - instead of durationLeft, pass just duration
        - incrementing, not decrementing
        - time units increase too: SSs, then MMmSSs, then HHhMMmSSs
  - measureCost:
     - instead of spending first 10% duration concurrently with main samplingGroup, orchestrator gives their duration a weight 0.1 when comparing with other progressGroups
     - i.e. measured 10 times less than main samplingGroups in average
  - not allowed if CONF.save true
  - no timing during measuring:
     - no process timeout
     - no `measureDurationLeft` in `maxDuration`
     - orchestrator does not check for samplingGroupEnd
  - print "Type CTRL-C to exit" below progress reporter
     - or equivalent key on Windows

CONF.concurrency NUM
  - validate that CONF.concurrency NUM is integer >=1
  - spawns NUM processes in parallel
     - in `bench` command, but not in `exec` command
     - start|end group of processes together
        - i.e. spawns only the process execution logic in parallel, not the whole performRun()
     - use same maxDuration and timeoutNs
     - if one process fails, the other ones should be terminated
     - measureCost computation should use the same amount of parallel processes
  - add code comment that:
     - CONF.concurrency is meant to measure cost of parallelism
        - both CPU and I/O parallelism
     - if task is I/O bound, it can also improve precision by performing more measures, at the cost of accuracy (due to cost of parallelism)
        - the number where parallel processes start competing for CPU depends on how much duration the task spend on CPU vs I/O
        - above that number:
           - median measure increases much more
           - precision decreases much more
     - move the current code comment from src/measure/combination.js (about spawning processes serially)
  - handle spawn errors due to too many processes at once
     - try to remove process limit with ulimit, and see if another error can happen with a high CONF.concurrency, e.g. too many open files

Sort all the code comments in `measure/**` and the `node|cli` runners. It's a bit messy right now, and some might be outdated

CONF.report|run|store|progress:
  - CONF.report|run|store|progress 'NAME'_ARR (enable|disable)
  - CONF.report|run|store|progress_NAME_PROP VAL (config)
     - can set config even if disabled. Does not enable.
  - reasons:
     - flat simpler than nesting
     - single delimiter character. No mixing several like - _ .
     - distinction selecting adapters vs configuring them
     - allow different users and programming languages to use prefered characters in ids
     - works unescaped with YAML and JSON
     - easy to understand when both CONF.VAR and CONF.report_{reporterId}-PROP are possible. The second is just like a selector/namespace
  - remove the `addRunners()` function which split CONF.run to CONF.run|runners
  - environment variables:
     - use _ as delimiter instead of __
     - no need for `set()` nesting anymore since all config properties are flat now

ID validation:
  - for user-defined (task|input|system|mergeId):
     - [[a-zA-Z0-9]._-]+
     - no empty string
  - for plugins (report|run|store|progress):
     - [a-z][a-z0-9]*
     - no empty string
     - no _
        - reason: not allowed in npm package name
        - reason: used as config property delimiter
     - no .
        - reason: not allowed in npm package name
     - no -
        - reason: confusing when mixed with _ delimiter in config properties
        - reason: not friendly in envvars
     - force module name to spyd-report|run|store|progress-NAME
  - default mergeId in CI:
     - use a more generic characters replacement logic, with a slugify library, using the list of allowed characters in mergeId

Add comment that we enforce [a-z][a-z0-9_]* in configuration property names
  - in core (as opposed to plugins), we try to avoid _ too
  - reasons:
     - no mixed case, because it is not common in CLI flags nor environment variables
     - consistent option name across spyd.yml, CLI flags, envvars, programmatic
     - no multiple delimiters

Validate that there are no duplicate ids for tasks|inputs|systems|propSets|runners
  - reason: allows using id only (without specifyig the type) in some contexts, e.g. CONF.include|exclude

runner.config.PROP.example STR[_ARR]
  - for all plugins: reporter, progress, runner, store
  - meant for validation, using jest-validate (same validation as for CONF.*):
     - validate against unknown props
     - if ARR, use multipleValidOptions()
  - required

CONF.system:
  - CONF.system "systemId [(systemTitle)]"
     - id does not need any no slugification
     - title is optional, and between parenthesis
     - def: "default_system (Default system):
        - note: default title not shown in core reporters (since sharedSystem is top-level)
        - reason: unlikely to conflict with a taskId or inputId
     - no variables
        - including {{ENV_VAR}}, {{os}}, {{os_full}}
        - instead can use:
           - shell, e.g. subshell and environment variable expansion
           - passing SPYD_SYSTEM environment variable from caller
  - reporting|measuring:
     - the current partialResult only uses one system: CONF.system
        - only `bench` command
     - CONF.include|exclude allows reporting several systems
        - `bench|show|remove` commands
        - either from current benchmark (with CONF.merge) or previous benchmarks
        - does not apply to measuring
        - current CONF.system always included
  - add comment that system is only for out-of-spyd env: hardware, OS, git branch, env vars, etc.

result.systems:
  - still an OBJ_ARR, one per systemId
  - result.systems[0] -> result.sharedSystem
     - created on results load
  - result.systems[*]:
     - id STR
     - title STR
        - def: same as id
     - machine: os|memory|cpu
     - versions OBJ
        - all runner.versions shallow merged
        - not versions.RUNNER.VAR: all runners shallow merge their versions OBJ, using CONF.run ARR order as priority order
     - git
        - not result.git
     - ci "URL"
        - not OBJ, and not result.ci
     - no more config nor runConfig
        - should use propSets instead

Remove commands dimension:
  - CONF.run_node_versions -> CONF.run_node_version (only one version)
  - runner.commands() returns a single OBJ instead of OBJ_ARR:
     - should use propSets instead to perform several runConfig
     - commands is not a input-like dimension anymore, including in:
        - combination.name|columnName
        - combination.commandRank
        - combination.previous
        - combinations sorting
        - duplication removal
        - commandId in CONF.limit
        - `show`/`remove` command filtering
        - result.commands[Pretty]
     - returned OBJ properties:
        - spawn ['FILE', 'ARG',...]
        - spawnOptions OBJ (def: {})
        - not needed anymore:
           - id -> not needed anymore since no more targetting
           - title|description -> runner.id|title
  - remove any instances of the word "command", except for CLI commands, to avoid confusion
     - commandConfig -> runConfig

runner.commands(runConfig):
  - rename to runner.launch(runConfig)
  - instead of returning [PROMISE_]OBJ, return [PROMISE_]STR, i.e. ['FILE', 'ARGS',... [, OBJ2]]
     - OBJ2 is optional spawnOptions
  - can optionally be directly a STR instead of FUNC()->[PROMISE_]STR

runner.versions
  - instead of runner.system
  - either OBJ or FUNC(runConfig, launchCommand)->[PROMISE_]OBJ
     - launchCommand is STR_ARR returned by runner.launch()
     - OBJ values can be either STR (direct value) or STR_ARR (command to retrieve stdout from, all called in parallel)
  - required
  - meant for software versions, mode (e.g. type of shell) and options

propSets:
  - name:
     - propSet: whole dimension
     - propItem: each item in a propSet
     - called "configuration property sets" in comments and documentation
  - specified by either:
     - passing ARR to specific CONF.*
        - validate no duplicate values in that ARR
     - merging results with different VALs for specific CONF.*
        - i.e. remove that results with different CONF.* cannot be merged
  - only on any CONF.* that can change the results:
     - CONF.concurrency
     - CONF.duration
        - not documented since this is generally not a good idea
        - however, this ensures that when merging results, different durations are clearly marked as such
     - any CONF.run_{runnerId}_*
        - cartesian product only to combinations with that runner
  - each propSet is a separate dimension, distinct from other propSets:
     - in CONF.include|exclude
     - in combination.columnName: several STR
     - result.propSets OBJ_ARR_ARR, not OBJ_ARR
     - combination.propSets ARR
  - propItemId:
     - property key appended by 0-based index, e.g. "concurrency_0" or "run_node_version_2"
        - index in current benchmark only (not previous ones)
        - when adding a new propItem through CONF.merge, use incremented index
     - used when selecting with CONF.include|exclude|limit
        - can optionally omit repeated part, e.g. concurrency_0,3,4
  - propItemValue:
     - property VAL
     - used as identifier when comparing between combinations (including between different benchmarks), using util.isStrictDeepEqual()
  - propItemTitle:
     - returned by runner.config.PROP.title(VAL)->STR
     - optional. Default function:
        - `${PROP} ${VAL}`
        - PROP is titleized, e.g. aa_bb_cc -> Aa bb cc
        - VAL: String() on STR|NUM|BOOL|null, max decimals on FLOAT
     - truncate result with ellipsis if too big
  - set on result.* like other dimensions:
     - for combinations sorting, mean, rank, selection, etc.
     - result.propSets OBJ_ARR_ARR: id STR, value VAL, title STR
     - combination.propSets OBJ_ARR: id STR, value VAL, title STR
  - just like tasks and inputs, only reported in main reporting table, not in system info below it
  - if several propItems have different runner.versions.VAR VAL, they are concatenated as a  result.systems[*].versions.VAR ARR
     - printed as a comma-separated list by reporter prettify logic
     - does not mention which propItem used which ones. It should be obvious enough from propItemTitles

Each task file should contain a single task
  - reason: lower loadCost
  - instead of exporting tasks OBJ_ARR, named exports:
     - before|main|after
     - isAsync BOOL
     - variables|shell (for CLI)
     - inputs ARR
  - runner.benchmark() does not need taskId anymore, only taskPath

CONF.include|exclude STR_ARR
  - possible combinations are cartesian product of: tasks, inputs, runners, propSets, systems
  - format:
     - CONF.include|exclude STR_ARR
        - def:
           - include: all
           - exclude: none
        - combination is used if included and not excluded
     - STR_ARR: does union
        - each STR do not need to share same dimensions
     - STR is a space-separated list of groups
        - groups are intersected
        - groups must all be from different dimensions
     - each group is a comma-separated list of IDs
        - all IDs must be from same dimension
        - can prepend ! to whole group to invert its selection
           - done before intersecting with other groups
        - no space allowed around comma
  - remove the special parsing with CLI flags to allow ARR values using comma-separated lists
  - no more need for:
     - CONF.tasks|inputs
     - task.inputs
  - CONF.limit should be STR_ARR with same format as CONF.include
     - except each STR is prepended with percentage (then space) and IDs are optional

CONF.settings "DIR"
  - def: first .[/...]/benchmark
     - "benchmark", not "benchmarks"
  - in CLI, is a normal flag (not positional)
  - remove CONF.cwd
  - used for task files
  - used for results file (SETTINGS/results.ndjson)
  - used as the cwd for CONF.output|insert
  - used for config file

Config file:
  - merge several:
     - in priority:
        - CLI flag --config
        - environment variables
        - CONF.settings/[.../]spyd.yml
        - ./[.../]spyd.yml
        - home dir  using `env-paths` `config`, i.e. /home/USER/.config/NAME, /Users/USER/Library/Preferences/NAME, C:/Users/USER/AppData/Roaming/NAME/Config
     - need two rounds, since CONF.settings/spyd.yml might be found using CONF.settings from other locations
  - shallow merge

CONF.run "RUNNER_ID"_ARR
  - default value
     - only bundled runners
        - reason: runners in CONF.run not installed fail, and we do not want to force npm installs
     - def: ["node", "cli"]
     - should not put several runners with same|shared EXTs
  - is a dimension, i.e. can CONF.include|exclude
     - only cartesian product to tasks with matching file extension
  - add code comment that we use explicit CONF.run instead of:
     - using code comment
        - bad performance with big files
        - transpiling removing comments
        - does not work in compiled binaries
     - using filenames:
        - does not work will with multiple runners per task
        - leads to odd filenames when runner and extension are similar|same
     - guessing using require()
        - too implicit/magic
        - would also find dependencies dependencies
        - does not work well with bundled runners

Task files selection:
  - SETTINGS[/*]/TASK_ID.task.[RUNNER.]EXT
     - allows for both regular files and 1-depth directories
  - no more CONF.files (CLI positional argument)
  - use `junk` to filter out
  - only task files with matching runners
     - only if present in CONF.run
     - based on runner.extensions "EXT"_ARR
        - EXT can have dot in it, e.g. 'EXT.EXT2'
     - can override with RUNNER in filename, in which case runner.extensions is ignored
        - must still be present in CONF.run
        - possible goals:
           - if runner.extensions does not contain the extension wanted by user
           - allow two files with same taskId, same file extension but different runners
              - e.g. taskId.task.node.js and taskId.task.browser.js
     - single task file can target several runners, which spawns several combinations
     - no errors if no matching runners
        - reason: selecting with CONF.run
  - validate that no two task files have same taskId + runner
     - but can have same taskId and different runner, or vice-versa
  - the resulting tasks can all be selected with CONF.include|exclude
  - no need to return taskId anymore in runner load()

inputs.yml:
  - instead of inputs inside tasks
  - located at SETTINGS/inputs.yml
  - use JSON_SCHEMA js-yaml option
  - OBJ_ARR: id STR, title STR, value VAL
  - runner.benchmark() gets `input` value instead of inputId
  - the resulting inputs can all be selected with CONF.include|exclude
     - no more need to return variationId|variationTitle from runner.load()

Return `title` in runner.benchmark()
  - no more need to return taskTitle from runner.load()
  - allow not returning it (parent process does the default value assignment)

loadCost sample
  - run before measureCost sample, only once
  - same behavior as measureCost but with maxDuration -1
  - used to retrieve:
     - initial value of loadCost
     - taskTitle

Remove runner.load():
  - after loadCost sample, returning `title` from runner.benchmark(), inputs.yml and CONF.include|exclude have made it unnecessary
  - remove event.type

CONF.info|context -> CONF.show STR_ARR among 'system', 'metadata'
  - if no:
     - 'system': pass `undefined` to reporters for result.sharedSystem|systems[*].machine|versions|spyd
     - 'metadata': pass `undefined` to reporters for result.sharedSystem|systems[*].git|ci and result.id|timestamp
  - default value:
     - has "system" if CONF.system defined
     - has "metadata" if `show|remove` command

Spyd link in reporter
  - should be presented as spyd version instead:
     - "Benchmarked by [spyd vX.Y.Z](URL to GitHub release)
  - persist result.spydVersion "X.Y.Z"
     - when merging, only the lowest one is kept
     - on load, normalized to results.spyd OBJ:
        - version "X.Y.Z"
        - release "URL" to GitHub release
  - remove CONF.link BOOL
     - instead, make it part of CONF.show "system"
        - when not present, result.spyd should be undefined
        - should also be undefined when printing to interactive terminal

Variables in `cli` runner:
  - remove user-defined `variables`. Can use either subshells, or command wrapper instead
  - add code comment that {{main}} is purposely not provided so users only put what they want to measure in main, not cleanup code for "after"
  - available variables (in lowest priority order):
     - {{ENV_VAR}}
        - use process.env as is, i.e. case sensitive on Unix, case insensitive on Windows
     - {{before}}, {{main}}
     - {{inputId}}

combination.name|columnName:
  - task dimension not present if all combinations have same value (like other dimensions)
     - exception: if single dimension, show only task
  - columnName order is input, system, runner, propSets
  - if there are runner-specific propSets
     - must be last
     - empty values (when on different runners) removed
        - i.e. different propSets for different runners might be aligned together
     - columnName arrays should all have same length, by appending empty strings
        - i.e. if one runner has 1 propSet, and another has 2, the first gets an empty string appended

Persist result.tasks|inputs|systems|commands:
  - only data which cannot be computed: id|title|description
     - mean|rank should be computed during load normalization instead
  - do not persist result.combinations[*].*Title|Description
     - add those during load normalization instead
     - only persist result.combinations[*].*Id|stats

Execute `listResults()` earlier:
  - after config retrieval
  - before:
     - `bench` command: combination list computing
     - `show|remove` command: retrieving specific result (i.e. split `getFromStore` into two)
  - reasons:
     - with CONF.merge, allows skipping already saved combinations
        - including when continuing stopped benchmark
     - show previous|diff during progress|live reporting
     - fail benchmark fast if problem with store

After listResults(), core should normalize partialResults to results:
  - perform an array of reducing functions:
     - meant for migration, when a new release of spyd is making changes to result properties
     - array is empty for the moment
  - filter by tasks|inputs|systems|propSets
  - sort by partialResult.timestamp
  - group partialResults to result using partialResult.mergeId
     - partialResult.id -> not kept in result
     - partialResult.mergeId -> result.id
  - silently filter out duplicate combinations (same mergeId+taskId+inputId+systemId+propItemValue)
     - reason: might happen if two results with same mergeId ran in parallel
     - keep one with earliest timestamp

store.add(result) -> store.add(partialResult)
  - i.e. append only, not merged with previous ones
  - same for addResult()

Add in comment and --help that CONF.merge is meant only for doing a single benchmark but incrementally:
  - parallelize benchmarks across identical machines (including in CI): same mergeId, same systemId
  - benchmark across different machines|hardware|software (including in CI): same mergeId, different systemId
  - continue stopped benchmark

When merging combination and there is a duplicate of same mergeId and taskId+inputId+systemId+propItemValue:
  - different os|cpu|memory|git:
     - throw and suggest to either use a different systemId, or make a different benchmark
     - reason: merge is meant for incremental benchmarks, i.e. combinations must be comparable
  - different CI build|job:
     - merge:
        - if one has no CI build|job URL, use other
        - if same CI job URL, use it
        - if same CI build URL, use it
        - if several CI build URLs, use the new one
     - reason: benchmark parallelized on several machines
  - different timestamp: keep earliest
  - different CONF.*:
     - if propItemValue: different propItems
     - otherwise: ignored
  - no difference check if different systemId
     - only appends to result.systems
     - reasons: using systems to compare machines, git branches, etc.

CONF.merge skipping previous combinations:
  - if CONF.merge in `bench` command, do not measure (but still report) combinations already saved
  - reason: CONF.merge is meant for incremental benchmarks, including continuing stopped benchmark

Stopping benchmark:
  - on `SIGINT`, `SIGBREAK`, `SIGHUP` or `SIGTERM`
     - either interactive TTY or not
     - including if CONF.duration 0
  - serialize current measuring state (including all `measures`) to file
     - in GLOBAL_CACHE_DIR/HASH/stopped_benchmark.json
        - HASH is SHA1 of normalized absolute file path of CONF.settings
  - only last stopped benchmark (for a given CONF.settings) is saved
  - CONF.continue BOOL:
     - if true and there is a stopped_benchmark.json, use it to continue the last stopped benchmark
     - must use similar settings
        - e.g. main config values (like duration), combinations ids
        - figure out the exact set of settings to compare.
           - some are ok to change, e.g. reporting-related
  - remove CONF.merge "" to mean "same|last result"

Deltas:
  - in `show|remove` commands, and CONF.since|diff
  - computed by core
  - based on listResults() output, after tasks|inputs|systems filtering
     - reason: if a user is doing `bench` always filtered for specific tasks|inputs|systems, without using CONF.merge (e.g.  each task is a library, and is only recomputed on a new version of the library), then `show` or default CONF.diff 1 should compare each combination to the latest which had same taskId|inputId|systemId
        - should document this, since it is an alternative to CONF.merge, with similar goals for settings slow or with many dimensions
  - can be:
     - absolute timestamp
     - relative duration like "3m"
     - NUM
     - mergeId
  - operates on results, not on partialResults
  - when using timestamps|duration, should retrieve the full result
     - even if some partialResult are before, some after the timestamp, for this specific result
  - delta which cannot be resolved should:
     - CONF.since: empty array
        - reason: allows not doing `sync` before `bench` in CI
     - CONF.diff: same as no diff
     - `show|remove`: error
  - for relative duration and NUM, base:
     - CONF.since|diff in `show|remove` command: shown result
     - otherwise, latest|now
  - for absolute|relative date: target the closest earlier (not later) result

CONF.since VAL
  - filters result.previous
     - does not impact other deltas resolution (`show|remove`, CONF.diff)
  - VAL is delta, or "" (def, no filtering)
  - same delta as `show|remove` commands
  - result.previous maximum timestamp should be currently shown result's
     - e.g. if `show|remove` command and CONF.since delta starts after `show|remove` delta, result.previous should be empty

Stores:
  - add comment that no support for multiple stores because not very useful and bring questions around data sync
  - add comment that no need to make addResults() concurrent safe. Reasons:
     - append will be concurrent safe on many situations since the number of bytes to write is fairly small
     - unlikely two benchmarks would end exactly at same time on same machine
     - not good practice to execute two benchmarks at same time on same machine
     - can easily fix it by doing a `sync`
  - store.start(storeConfig) -> FUNC(storeConfig)->store instead (closure)
  - always saved at SETTINGS/results.ndjson
  - results use ndjson format. Reasons:
     - JSON parsing much faster than YAML
     - appending a file is much faster than writing the whole file
  - results file vs store:
     - results file logic is not considered a store
        - built-in, not configurable except for file location
        - not loaded like the stores
        - uses functions: addResult(), listResults(), removeResult(), syncResults()
           - result file location is passed as argument (no start())
     - listResults() at the beginning of `bench|show|remove`
        - load full|unfiltered data
     - if CONF.save true:
        - await store.add()
        - if no error, then do addResult()
     - `remove` command:
        - await store.remove()
        - if no error, then do removeResult()
     - `sync` command:
        - store.list()->OBJ_ARR
           - load full|unfiltered data
        - then syncResults(OBJ_ARR)
           - no more store.replace() method

CONF.quiet true:
  - for all commands
  - effect:
     - no console.log()
        - no logs on `exec` command
        - exception: errors are still printed
     - CONF.progress|report forces to empty ARR
  - remove CONF.progress|report "silent"

Reporting on `remove` command:
  - call reporters, like `show`
  - then prompt for removal confirmation
     - unless CONF.force true
  - then print confirmation removal suceeded
     - unless CONF.quiet true

CONF.run-cli.shell:
  - instead of taskFile.shell
  - STR instead of BOOL: "none", "sh", "bash"
  - should default to "none" instead
  - `cli` runner.versions:
     - if "none": none
     - if "bash|sh": { Bash|sh: 'X.Y.Z'}

Plugin shape should be validated:
  - including that plugin properties values cannot be:
     - OBJ
        - reason: nesting does not work well in CLI flags or envvars
     - ARR
        - reason: used for propSets
  - including that plugin properties names must be [a-z][a-z0-9_]*

Error handling:
  - better way for all plugins (report, progress, stores, runners) to signal user error vs bugs
  - better handling of child process errors due to runner bugs (handled as user error right now)
  - plugin|core errors should print message to report GitHub issues to the plugin|core
     - it should include system information

CONF.debug BOOL
  - add debug information, for bug reports
  - add to issue template
  - for all actions
  - print:
     - resolved config
     - task files
     - runner.versions
     - combinations
     - each sample's state (including maxDuration, repeat, etc.)
     - last result, new partialResult, new result
  - do not call reporters

Learn package 'simple-statistics' and use it in spyd???

When killing child process, should kill descendants too
  - e.g. with spyd-runner-cli and command 'yes', 'yes' keeps executing after timeout

Consider lowering the valid Node version for spyd-runner-node, so that `run.node.versions` can target lower versions

Add REPL to evaluate Node.js or `cli` runner task on-the-fly???
  - should allow OPTS.save, so differences are shown

Create a store that works in GitHub actions???

Add progress reporters:
  - spinner with task name and current median
  - progress bar
  - both above (def)

Reporters:
  - types:
     - JSON
     - CLI list
     - CLI table
     - Markdown list
     - Markdown table
     - CLI graphs|histograms
     - CLI where the tasks are in both axis, and the cells are the difference in %
     - CLI with horizontal bars for medians
        - with full CLI width for slowest median
        - still show numbers on top of bars (or on their left side)
        - def reporter instead of simple CLI list, except when there is only one combination
        - for Markdown too???
     - HTML
     - CLI time series (with previous combinations)
  - CLI|Markdown list:
     - follow the formatting I used in fast-cartesian example
        - simple list for TASK with no inputs
  - CLI|Markdown tables:
     - inputs as x axis, tasks as y axis
  - default reporter:
     - CLI|Markdown table if more than half of cells would be filled, and some TASK.inputs are defined
        - CLI|Markdown list otherwise
     - Markdown table|list if CONF.insert '*.md|*.markdown|README|readme'
        - CLI table|list otherwise

Make `precise-now` work on browser + node

Split `precise-timestamp` to own repository
  - make it work on browser + node
  - problem with browser: performance.now() is made only ms-precise by browser due to security timing attacks

Separate into different repos:
  - some plugins are builtin, i.e. required as production dependencies by core
     - including spyd-run-node and spyd-run-cli (until more runners are created)
  - types: spyd-report|progress|run|store-*
  - spyd -> spyd (CLI) + spyd-core (non-CLI)

Clarify features in `README`:
  - most precise and accurate benchmarking
  - pretty reporting
  - comparison with previous results
  - performance testing
  - automatically insert latest results into your documentation
  - custom reporters
  - TypeScript support
  - CI-friendly

Add tests, documentation, etc.:
  - for all repos, including sub-repos
  - add keywords (GitHub, package.json)

Use key-value abstraction layers to add more built-in spyd-store-*

Utilities to help people creating reporters, runners, progress reporters, stores
  - GitHub template
  - test utility

Competitors benchmark:
  - benchmark with other benchmarking tools
  - each should measure Math.random() for the same duration
     - use different durations as inputs
  - report both medians (for accuracy) and standard deviation (for precision)

Add roadmap:
  - point to it from contribution doc to orient contributors towards features I want (e.g. HTML reporter)

Promote

Add other runners:
  - spyd-run-chrome (maybe using puppetter)
  - spyd-run-firefox (maybe using puppetter-firefox)
  - spyd-run-selenium
  - spyd-run-bash
  - spyd-run-go

Commercial offer:
  - reporting dashboard:
     - show time series (i.e. keep history)
        - should not lose history when change only the `title` of the function|variant
     - nice data visualization
     - should show function bodies
  - code editor for tasks files:
     - perform benchmark (inside browser not on our servers)
     - send results to API (like what users would do on CI otherwise)
     - show results from API
     - i.e. can be used like jsperf
  - Sharing like jsperf:
     - allow users to benchmark in their own browsers
  - PR bot
  - notifications
  - user should report results to our API
     - like Codecov does
     - i.e. we do not pay for infrastructure cost, except simple CRUD API to store results
     - should be integrated with CI (i.e. use `ci-info`)
  - pricing:
     - free for open source
     - pay per private repo
