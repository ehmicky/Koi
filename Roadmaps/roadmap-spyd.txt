
        
   SPYD  
        



UX feedback:
  - dot notation for --report.json --report.json.output???
  - --limit should be an integer, not a string???
  - --group is confusing
     - rename it???

Then seems to be a bug with task selection???
  - when using spyd-run-cli with a benchmark file with no variation, --tasks have to be specified

Find a way so users don't have to manually select runners
  - maybe automatically load any spyd-run-* then:
     - figure out which one to use by file extension???
     - allow runner to specify additional logic, e.g. Node.js runner try to find require() statements???
     - allow disabling with --run.RUNNER.disabled???

OPTS.report|run|store|progress:
  - OPTS.report|run|store|progress 'NAME'_ARR (enable|disable)
  - OPTS.report|run|store|progress-NAME OBJ (options)
     - can set options even if disabled. Does not enable
  - NAME:
     - validated to [a-z][a-z0-9-]*
     - force module name to spyd-reporter-NAME
        - @scope???

Use a `config` library instead of using our own logic

Learn package 'simple-statistics' and use it in spyd

Use git provider assets in CI for spyd-store-*:
  - e.g. GitHub action download|upload-artifact
     - or Travis download artifacts

Separate into different repos:
  - some plugins are builtin, i.e. required as production dependencies by core
     - including spyd-run-node and spyd-run-cli (until more runners are created)
  - types:
     - spyd-report-*
     - spyd-run-*
     - spyd-store-*
     - spyd-progress-*
  - spyd -> spyd (CLI) + spyd-core (non-CLI)

Add progress reporters:
  - spinner with task name and current median
  - progress bar
  - both above (def)

Reporters:
  - types:
     - JSON
     - CLI list
     - CLI table
     - Markdown list
     - Markdown table
     - CLI graphs|histograms
     - CLI where the tasks are in both axis, and the cells are the difference in %
     - CLI with horizontal bars for medians
        - with full CLI width for slowest median
        - still show numbers on top of bars (or on their left side)
        - def reporter instead of simple CLI list, except when there is only one iteration
        - for Markdown too???
     - HTML
     - CLI time series (with previous iterations)
  - CLI|Markdown list:
     - follow the formatting I used in fast-cartesian example
        - simple list for TASK with no variations
  - CLI|Markdown tables:
     - variations as x axis, tasks as y axis
  - default reporter:
     - CLI|Markdown table if more than half of cells would be filled, and some TASK.variations are defined
        - CLI|Markdown list otherwise
     - Markdown table|list if OPTS.insert '*.md|*.markdown|README|readme'
        - CLI table|list otherwise
  - when BENCHMARK.histogram|percentiles [], reporters should show "Not enough data" (but not throw)
  - Markdown|HTML reporters should add "Benchmarked with [spyd](https://github.com/ehmicky/spyd)" when REPORTER_OPTS.link true
     - but CLI reporters should never add anything (except 'debug' reporter)

When killing child process, should kill descendants too
  - e.g. with spyd-runner-cli and command 'yes', 'yes' keeps running after timeout

Competitors benchmark:
  - benchmark with other benchmarking tools
  - each should benchmark Math.random() for the same duration
     - use different durations as variations
  - report both medians (for accuracy) and standard deviation (for precision)

Add tests, documentation, etc.:
  - for all repos, including sub-repos

Consider lowering the valid Node version for spyd-runner-node, so that `run.node.versions` can target lower versions

Utilities to help people creating reporters, runners, progress reporters, stores
  - GitHub template
  - test utility

Add other runners:
  - spyd-run-chrome (maybe using puppetter)
  - spyd-run-firefox (maybe using puppetter-firefox)
  - spyd-run-selenium
  - spyd-run-bash

Add roadmap:
  - point to it from contribution doc to orient contributors towards features I want (e.g. HTML reporter)

Promote:
  - add keywords (GitHub, package.json)

Features:
  - most precise and accurate benchmarking
  - pretty reporting
  - comparison with previous benchmarks
  - performance testing
  - automatically insert latest benchmarks into your documentation
  - custom reporters
  - TypeScript support
  - CI-friendly

Commercial offer:
  - reporting dashboard:
     - show time series (i.e. keep history)
        - should not lose history when change only the `title` of the function|variant
     - nice data visualization
     - should show function bodies
  - code editor for benchmark files:
     - run benchmarks (inside browser not on our servers)
     - send benchmark results to API (like what users would do on CI otherwise)
     - show results from API
     - i.e. can be used like jsperf
  - Sharing like jsperf:
     - allow users to run in their own browsers
  - PR bot
  - notifications
  - user should report benchmark results to our API
     - like Codecov does
     - i.e. we do not pay for infrastructure cost, except simple CRUD API to store benchmark results
     - should be integrated with CI (i.e. use `ci-info`)
  - pricing:
     - free for open source
     - pay per private repo
